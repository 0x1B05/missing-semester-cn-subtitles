1
00:00:00,900 --> 00:00:04,627
好的,欢迎来到今天的讲座,
All right, so welcome to today's lecture 

2
00:00:04,627 --> 00:00:06,650
我们将会讲解数据整理(Data Wrangling).
which is going to be on data wrangling. 

3
00:00:06,650 --> 00:00:10,100
"数据整理"这个词可能听起来有点奇怪,
And data wrangling might be a phrase that sounds a little bit odd to you, 

4
00:00:10,100 --> 00:00:14,125
但它的基本想法是,你有一种格式的数据,
but the basic idea of data wrangling is that you have data in one format 

5
00:00:14,125 --> 00:00:16,250
你要它把它转化成另一种格式的数据,
and you want it in some different format, 

6
00:00:16,250 --> 00:00:18,200
这种情况非常常见.
and this happens all of the time. 

7
00:00:18,200 --> 00:00:20,575
我不仅指转换图像,
I'm not just talking about like converting images, 

8
00:00:20,575 --> 00:00:23,800
还可能是你有一个文本文件或日志文件,
but it could be like you have a text file or a log file 

9
00:00:23,800 --> 00:00:26,618
但是你想得到这些数据的其他的格式,
and what you really want this data in some other format. 

10
00:00:26,618 --> 00:00:29,750
例如图表或对数据进行统计.
Like you want a graph or you want statistics over the data. 

11
00:00:29,750 --> 00:00:33,385
任何把一种格式的数据
Anything that goes from one piece of data 

12
00:00:33,385 --> 00:00:38,150
转换成另一种格式的数据的过程都可以被称为"数据整理".
to another representation of that data is what I would call data wrangling. 

13
00:00:38,150 --> 00:00:43,400
在前面几节课,我们已经看到了一些数据整理的例子,
We've seen some examples of this kind of data wrangling already previously in the semester, 

14
00:00:43,400 --> 00:00:46,600
例如当你使用管道操作符时,
like basically whenever you use the pipe operator 

15
00:00:46,600 --> 00:00:50,750
它可以让你把一个程序的输出传递给另一个程序,
that lets you sort of take output from one program and feed it through another program, 

16
00:00:50,775 --> 00:00:53,475
这是做数据整理的一种方式.
you are doing data wrangling in one way or another. 

17
00:00:53,475 --> 00:00:56,325
但是在这节课上,
But what we're going to do in this lecture is take a look at 

18
00:00:56,325 --> 00:01:02,600
我们将会学到更高级,更实用的数据整理方法.
some of the fancier ways you can do data wrangling \N and some of the really useful ways you can do data wrangling. 

19
00:01:02,600 --> 00:01:07,375
要进行数据整理,首先你都需要有一个数据源.
In order to do any kind of data wrangling, though, you need a data source. 

20
00:01:07,375 --> 00:01:09,850
你需要先有一些数据才能进行操作.
You need some data to operate on in the first place, 

21
00:01:09,850 --> 00:01:14,475
有很多可以选择的数据,
and there are a lot of good candidates for that kind of data. 

22
00:01:14,475 --> 00:01:18,250
我们在讲座笔记的练习中就给出了一些例子.
We give some examples in the exercise section for today's lecture notes. 

23
00:01:18,250 --> 00:01:22,200
今天,我将使用一个系统日志.
In this particular one, though, I'm going to be using a system log. 

24
00:01:22,200 --> 00:01:25,555
我有一台在荷兰运行的服务器,
So, I have a server that's running somewhere in the Netherlands 

25
00:01:25,555 --> 00:01:28,093
这个选择在当时来看十分合理.
because that seemed like a reasonable thing at the time, 

26
00:01:28,093 --> 00:01:30,020
在那台服务器上,
and on that server, 

27
00:01:30,020 --> 00:01:34,825
它通过"systemd"运行了一个日志守护进程,
it's running sort of a regular logging daemon that comes with "systemd". 

28
00:01:34,825 --> 00:01:37,750
这是一个相对标准的Linux日志机制,
It's a sort of relatively standard Linux logging mechanism, 

29
00:01:37,750 --> 00:01:43,950
有一个名为{\rcode}journalctl{\r}的命令,可以让你查看系统日志.
and there's a command called "journalctl" on Linux systems that will let you view the system log. 

30
00:01:43,950 --> 00:01:48,225
所以我将对该日志进行一些转换,
And so what I'm gonna do is I'm gonna do some transformations over that log 

31
00:01:48,225 --> 00:01:50,650
看看是否可以从中提取出一些有趣的东西.
and see if we can extract something interesting from it. 

32
00:01:50,650 --> 00:01:56,475
{\rstrange}然而,你会看到,如果我运行这个命令,我会得到很多数据,{\r}
You'll see, though, that if I run this command, I end up with a lot of data 

33
00:01:56,475 --> 00:02:01,679
{\rstrange}因为这个日志包含了很多东西,对吧?{\r}
because this is a log that has just like there's a lot of stuff in it, right? 

34
00:02:01,679 --> 00:02:03,300
{\rstrange}在我的服务器上发生了很多事,{\r}
A lot of things have happened on my server, 

35
00:02:03,300 --> 00:02:06,075
{\rstrange}你看这条记录的开头是一月份,{\r}
and this goes back to like January first, 

36
00:02:06,075 --> 00:02:08,550
{\rstrange}有的日志还记录了更早的事件.{\r}
and there are logs that go even further back on this. 

37
00:02:08,550 --> 00:02:09,725
{\rstrange}这里有很多记录.{\r}
There's a lot of stuff. 

38
00:02:09,725 --> 00:02:15,075
{\rstrange}所以我们要做的第一件事情是对这个日志进行一些过滤.{\r}
So the first thing we're gonna do is try to limit it down to only one piece of content. 

39
00:02:15,100 --> 00:02:17,300
在这里,我们将使用"grep"命令.
And here the "grep" command is your friend. 

40
00:02:17,300 --> 00:02:21,700
我们用管道把"ssh"的输出连接到"grep"上.
So we're gonna pipe this through "grep", \Nand we're gonna pipe for ssh, right? 

41
00:02:21,700 --> 00:02:24,450
过去我们并没有正式介绍过ssh
So ssh we haven't really talked to you about yet, 

42
00:02:24,450 --> 00:02:27,800
但是我们知道,"ssh"是一种通过命令行远程访问计算机的方式.
but it is a way to access computers remotely through the command line. 

43
00:02:27,800 --> 00:02:32,700
特别是当你将服务器放在公网上时,
And in particular, what happens when you put a server on the public Internet is that 

44
00:02:32,700 --> 00:02:36,750
全世界的人都可以试图连接并登录你的服务器.
lots and lots of people around the world try to connect to it and log in and take over your server. 

45
00:02:36,750 --> 00:02:39,800
因此,我想看看这些人是怎么做的,
And so I want to see how those people are trying to do that, 

46
00:02:39,800 --> 00:02:41,750
所以我要使用"grep"搜索"ssh".
and so I'm going to "grep" for ssh, 

47
00:02:41,750 --> 00:02:44,532
很快你就会看到,
and you'll see pretty quickly that

48
00:02:44,532 --> 00:02:47,600
这会生成一大堆东西,至少理论上应该很快.
 this also generates a bunch of content, at least in theory.

49
00:02:47,600 --> 00:02:48,628
这会生成一大堆东西,至少理论上应该很快.

50
00:02:48,628 --> 00:02:52,050
真慢.
This is gonna be real slow. 

51
00:02:52,050 --> 00:02:53,575
就像这样.
There we go. 

52
00:02:53,575 --> 00:02:57,725
你可以看到它生成了这么一坨的内容,
So this generates tons and tons and tons of content, 

53
00:02:57,725 --> 00:03:01,125
光看到那么多内容就感觉头疼.
and it's really hard to even just visualize what's going on here. 

54
00:03:01,125 --> 00:03:06,225
现在,让我们只来看看人们连接服务器时使用的用户名.
So let's look at only what user names people have used to try to log into my server. 

55
00:03:06,225 --> 00:03:12,300
所以,你会看到其中一些行显示为已断开连接的无效用户,
So you'll see some of these lines say disconnected, disconnected from invalid user, 

56
00:03:12,300 --> 00:03:13,600
然后后面是某个用户名.
And then, some user name. 

57
00:03:13,600 --> 00:03:16,325
现在我只想要这种日志记录.
I want only those lines, that's all I really care about. 

58
00:03:16,325 --> 00:03:19,050
不过,我还要进行一些优化.
I'm gonna make one more change here though, 

59
00:03:19,050 --> 00:03:22,124
要想想这条命令流水线是如何工作的,
which is if you think about how this pipeline does, 

60
00:03:22,125 --> 00:03:28,225
如果我在这里加上"Disconnect from"(断开连接),
if I here do this connected from, so this pipeline at the bottom here, 

61
00:03:28,225 --> 00:03:33,625
首先整个日志文件都会通过先网络传到我的电脑,
what that will do is it will send the entire log file over the network to my machine 

62
00:03:33,625 --> 00:03:37,551
然后在本地运行"grep"来仅查找包含"ssh"的行,
and then locally run "grep" to find only the lines to contained "ssh" 

63
00:03:37,551 --> 00:03:39,800
然后在本地进一步过滤它们.
and then locally filter them further. 

64
00:03:39,800 --> 00:03:43,350
这似乎有点浪费,因为我不关心日志中的其他部分,
This seems a little bit wasteful because I don't care about most of these lines, 

65
00:03:43,350 --> 00:03:45,575
而且服务器也在运行shell,
and the remote site is also running a shell, 

66
00:03:45,575 --> 00:03:51,225
所以我可以直接在服务器上运行整个命令.
so what I can actually do is I can have that entire command run on the server. 

67
00:03:51,225 --> 00:03:56,550
因此,我会告诉ssh,在服务器上运行这三个管道操作,
Right, so I'm telling you,  the command I want you to run on the server is this pipeline of three things, 

68
00:03:56,600 --> 00:03:59,825
然后将返回的数据通过管道接到"less"上面.
and then what I get back, I want to pipe through "less". 

69
00:03:59,825 --> 00:04:04,120
这行命令干了啥?实际上是一样的数据筛选,
So, what does this do? Well, it's gonna do that same filtering that we did, 

70
00:04:04,120 --> 00:04:05,775
不过它先在服务器端运行,
but it's gonna do it on the server side, 

71
00:04:05,775 --> 00:04:09,900
最后将我想要的那些行发送给我.
and the server is only going to send me those lines that I care about. 

72
00:04:09,900 --> 00:04:15,475
然后,我在本地通过管道把这些行输入到"less",就可以分页查看.
And then when I pipe it locally through the program called "less", "less" is a pager. 

73
00:04:15,500 --> 00:04:18,825
你已经看到过一些使用"less"的例子,
You'll see some examples of this, you've actually seen some of them already, 

74
00:04:18,825 --> 00:04:22,575
比如当你输入"man"命令时,它就会在一个分页器中打开,
like when you type "man" and some command that opens in a pager, 

75
00:04:22,575 --> 00:04:28,200
分页是一种便于阅读的方式,可以将长篇内容适应到你的终端窗口中,
and a pager is a convenient way to take a long piece of content and fit it into your term window 

76
00:04:28,200 --> 00:04:33,875
并让你滚动和浏览,而不是直接滚过你的屏幕.
and have you scrolled down and scroll up and navigate it \N so that it doesn't just like scroll past your screen. 

77
00:04:33,875 --> 00:04:37,100
因此,如果我运行这个命令,我们仍然需要等待一段时间,
And so, if I run this, it still takes a little while 

78
00:04:37,100 --> 00:04:39,100
因为它必须解析大量的日志文件.
because it has to parse through a lot of log files, 

79
00:04:39,100 --> 00:04:46,600
而且,"grep"需要对输出进行缓存,所以它还卡在这儿.
and in particular, grep is buffering and therefore it decides to be relatively unhelpful. 

80
00:04:46,600 --> 00:04:57,275
我试试加一些标志,看看会不会好一些.
I may do this... Let's see if that's more helpful. 

81
00:04:57,275 --> 00:05:02,875
为啥还这样?
Why doesn't it want to be helpful to me? 

82
00:05:02,875 --> 00:05:08,800
好吧,我要搞点手段了,你们假装没看见,
Fine, I'm gonna cheat a little, just ignore me. 

83
00:05:17,825 --> 00:05:21,375
网速真的很慢.
Or the internet is really slow, those are two possible options. 

84
00:05:21,375 --> 00:05:28,800
还好,有个解决办法,上课前我已经运行了这个命令.
Luckily, there's a fix for that because previously I have run the following command. 

85
00:05:28,800 --> 00:05:33,449
这个命令将匹配所有包含"Disconnect from"的ssh日志条目,
So this command just takes the output of that command 

86
00:05:33,449 --> 00:05:35,700
并将其保存在我本地的一个文件中.
and sticks it into a file locally on my computer. 

87
00:05:35,700 --> 00:05:37,875
我先前在我的办公室运行了这个命令,
Alright, so I ran this when I was up in my office, 

88
00:05:37,875 --> 00:05:39,524
这样做的目的是
and so what this did is

89
00:05:39,524 --> 00:05:44,325
下载所有包含"Disconnect from"的ssh日志记录到本地,
 it downloaded all of the SSH log entries that matched "Disconnect from", 

90
00:05:44,325 --> 00:05:45,571
因此我本地拥有了这些记录,
so I have those locally, 

91
00:05:45,571 --> 00:05:47,250
这非常方便,对吧?
and this is really handy, right? 

92
00:05:47,250 --> 00:05:50,125
没有必要每次都流式传输整个日志,
There's no reason for me to stream the full log every single time 

93
00:05:50,125 --> 00:05:53,450
因为我只要匹配"Disconnect from"的行.
because I know that that starting pattern is what I'm going to want anyway. 

94
00:05:53,450 --> 00:05:56,450
现在,我们可以查看"ssh.log"文件,
So we can take a look at "ssh.log", 

95
00:05:56,450 --> 00:06:00,875
你会看到有很多很多行,都说"Disconnected from",
and you will see there are lots and lots and lots of lines that all say "Disconnected from", 

96
00:06:00,875 --> 00:06:02,875
"invalid user","authenticating users"等等.
"invalid user", "authenticating users", etc., right? 

97
00:06:04,375 --> 00:06:07,212
这些是我们需要处理的行,
So these are the lines that we have to work on, 

98
00:06:07,212 --> 00:06:11,325
这也意味着等会我们不必再走整个ssh的流程.
and this also means that going forward, we don't have to go through this whole SSH process. 

99
00:06:11,325 --> 00:06:14,325
我们只需要"cat"(查看)那个文件,然后再进行操作.
We can just cat that file and then operate it on it directly. 

100
00:06:14,325 --> 00:06:18,500
在这里我还可以演示一下这个分页器.
So here I can also demonstrate this pager, 

101
00:06:18,500 --> 00:06:23,175
如果我运行{\rcode}cat ssh.log{\r}并将其用管道连接"less",
so if I do cat s is a cat `cat ssh.log` and I pipe it through "less", 

102
00:06:23,175 --> 00:06:26,000
它会让我分页阅读,还可以上下滚动.
it gives me a pager where I can scroll up and down. 

103
00:06:26,000 --> 00:06:31,450
可以把字体变小一点,这样我可以滚动浏览整个文件了.
Make that a little bit smaller maybe so I can scroll this file screw through this file,

104
00:06:31,450 --> 00:06:34,800
我还可以使用Vim的按键来浏览,
And I can do so with what are roughly Vim bindings. 

105
00:06:34,800 --> 00:06:37,850
比如"Ctrl+U"向上滚动,"Ctrl+D"向下滚动,
So, "Ctrl+U" to scroll up, "Ctrl+D" to scroll down, 

106
00:06:37,850 --> 00:06:39,600
"q"退出.
and "q" to exit. 

107
00:06:39,600 --> 00:06:44,225
但是这依然是一大坨,
This is still a lot of content though, 

108
00:06:44,225 --> 00:06:47,550
而且这些行里有我不感兴趣的垃圾信息.
and these lines contain a bunch of garbage that I'm not really interested in. 

109
00:06:47,550 --> 00:06:50,525
我真正想看到的是这些用户名.
What I really want to see is what are these user names. 

110
00:06:50,525 --> 00:06:54,625
这里,我们要开始使用的工具叫做"sed".
And here, the tool that we're going to start using is one called "sed". 

111
00:06:54,625 --> 00:07:02,000
"sed"是一个流编辑器,它改良自更早的一个叫作"ed"程序,
"sed" is a stream editor that modifies or is a modification of a much earlier program called "ed", 

112
00:07:02,000 --> 00:07:06,275
后者是一个非常奇怪的编辑器,你们可能都不想使用.
which was a really weird editor that none of you will probably want to use. 

113
00:07:06,275 --> 00:07:10,667
[学生提问:"tsp"是啥玩意儿?]

114
00:07:10,667 --> 00:07:14,616
"tsp"是我正在连接的远程计算机的名称.
Yeah, Oh "tsp" is the name of the remote computer I'm connecting to. 

115
00:07:16,000 --> 00:07:19,050
所以"sed"是一个流编辑器,
So, "sed" is a stream editor, 

116
00:07:19,100 --> 00:07:25,100
它允许你修改流的内容.
and it basically lets you make changes to the contents of a stream. 

117
00:07:25,100 --> 00:07:28,200
你可以将其视为文本替换,
You can think of it a little bit like doing replacements, 

118
00:07:28,200 --> 00:07:32,700
但实际上它是运行在流上的一个完整的编程语言.
but it's actually a full programming language over the stream that is given.

119
00:07:32,700 --> 00:07:36,008
"sed"最常见的操作
One of the most common things you do with "sed" though is

120
00:07:36,008 --> 00:07:39,650
就是在输入流上执行替换表达式.
to just run replacement expressions on an input stream. 

121
00:07:39,650 --> 00:07:41,375
这是什么样子的呢?
What do these look like? 

122
00:07:41,375 --> 00:07:43,375
好的,让我给你展示一下.
Well, let me show you. 

123
00:07:44,608 --> 00:07:47,383
这里,我将管道连接到到"sed",
Here, I'm gonna pipe this to "sed", 

124
00:07:47,383 --> 00:07:53,933
然后比如说我想要删除"Disconnected from"之前的所有内容.
and I'm going to say that I want to remove everything that comes before "Disconnected from". 

125
00:07:56,944 --> 00:07:58,944
这可能有点奇怪.
This might look a little weird. 

126
00:07:58,944 --> 00:08:03,560
我们可以看到,日志里记录的日期,主机名
The observation is that the date and the hostname and

127
00:08:03,560 --> 00:08:06,435
和进程ID,我不关心这些.
the sort of process ID of the ssh daemon, I don't care about. 

128
00:08:06,435 --> 00:08:08,160
我可以直接删除它们,
I can just remove that straightaway, 

129
00:08:08,160 --> 00:08:11,610
还可以删除"Disconnected from"那一部分,
and I can also remove that "Disconnected from" bit 

130
00:08:11,610 --> 00:08:13,960
因为似乎每个日志条目中都包含这个.
because that seems to be present in every single log entry. 

131
00:08:13,960 --> 00:08:15,585
所以我想...
So I just want to give a little bit.

132
00:08:15,585 --> 00:08:18,244
所以我写了一个"sed"表达式.
So, what I write is a "sed" expression. 

133
00:08:18,244 --> 00:08:22,510
在这种情况下,它是一个"s/"表达式,即一个替换表达式.
In this particular case, it's an "s/" expression, which is a substitute expression. 

134
00:08:22,510 --> 00:08:27,960
它有两个以"/"分割的参数.
It takes two arguments that are basically enclosed in these slashes. 

135
00:08:27,985 --> 00:08:30,735
因此,第一个"/"后是搜索字符串,
So, the first one is the search string, 

136
00:08:30,735 --> 00:08:33,560
第二个"/"后是要换成的字符串,目前是空.
and the second one, which is currently empty, is a replacement string. 

137
00:08:33,560 --> 00:08:38,610
所以,在这里,我是说按这个模式搜索字符串并将其替换为空,
So, here, I'm saying search for the following pattern and replace it with blank, 

138
00:08:38,610 --> 00:08:41,335
然后在最后将其接到"less"上.
and then I'm gonna pipe it into "less" at the end. 

139
00:08:41,335 --> 00:08:46,060
看到了吗?现在它已经删除了所有这些行的开头.
Do you see that? Now, what it's done is trim off the beginning of all these lines, 

140
00:08:47,025 --> 00:08:49,550
这看起来非常方便.
and that seems really handy. 

141
00:08:49,550 --> 00:08:54,300
但你可能会想,我构建的这个模式是啥玩意儿?
But you might wonder, what is this pattern that I've built up here, right? 

142
00:08:54,300 --> 00:08:57,300
这个".*"又是啥玩意儿?
This is this dot star. 

143
00:08:57,300 --> 00:09:00,200
这是一个正则表达式的例子.
This is an example of a regular expression. 

144
00:09:00,200 --> 00:09:04,850
在编程中你可能已经接触过正则表达式,
And regular expressions are something that you may have come across in programming in the past, 

145
00:09:04,850 --> 00:09:07,600
但是一旦进入命令行,
but it's something that once you go into the command line, 

146
00:09:07,600 --> 00:09:11,125
你需要经常使用它来进行数据整理.
you will find yourself using a lot, especially for this kind of data wrangling. 

147
00:09:11,125 --> 00:09:16,100
正则表达式本质上是一种强大的匹配文本的方法.
Regular expressions are essentially a powerful way to match text. 

148
00:09:16,100 --> 00:09:18,925
你可以用它来匹配其他东西,
You can use it for other things than text too, 

149
00:09:18,925 --> 00:09:20,200
但文本是最常见的例子.
but text is the most common example. 

150
00:09:20,200 --> 00:09:26,450
在正则表达式中,有许多特殊字符,
And in regular expressions, you have a number of special characters 

151
00:09:26,450 --> 00:09:29,625
它们不仅可以匹配单个字符,
that say don't just match this character, 

152
00:09:29,650 --> 00:09:34,450
还可以匹配特定类型的字符或字符串.
but match, for example, a particular type of character or a particular set of options. 

153
00:09:34,450 --> 00:09:38,600
它本质上是生成一个程序,用于搜索给定的文本.
It essentially generates a program for you that searches the given text. 

154
00:09:38,600 --> 00:09:42,850
例如,"."表示任意单个字符,
Dot, for example, "." means any single character, 

155
00:09:43,735 --> 00:09:45,060
接着是"*"
and "*", 

156
00:09:45,060 --> 00:09:47,356
如果你在一个字符后面加上"*",
if you follow a character with a star, 

157
00:09:47,356 --> 00:09:50,735
它就表示匹配零次或多次该字符.
it means zero or more of that character. 

158
00:09:50,735 --> 00:09:53,710
因此,在这种情况下,".*"就表示零个或多个任意字符,
And so  in this case, this pattern is saying zero 

159
00:09:53,735 --> 00:09:59,060
后面跟着字面上的字符串"Disconnected from".
or more of any character followed by the literal string "Disconnected from". 

160
00:09:59,110 --> 00:10:03,310
我要找到这样的字符串,然后把他们替换为空.
I'm saying match that and then replace it with blank. 

161
00:10:03,360 --> 00:10:07,585
正则表达式有许多这种特殊字符,有各种不同的含义.
Regular expressions have a number of these kinds of special characters 

162
00:10:07,585 --> 00:10:09,960
你可以使用它们.
that have various meanings you can take advantage of them. 

163
00:10:09,960 --> 00:10:12,360
我提到了"*",表示匹配零次或多次,
I talked about star, which is zero or more. 

164
00:10:12,360 --> 00:10:14,760
还有"+",表示匹配一次或多次,
There's also Plus, which is one or more,

165
00:10:14,760 --> 00:10:18,210
也就是说至少匹配一次前面的模式.
This is saying I want the previous expression to match at least once. 

166
00:10:18,210 --> 00:10:21,535
你还可以使用"[]"来匹配多种字符中的一种.
You also have square brackets. 

167
00:10:21,535 --> 00:10:25,885
"[]"可让你匹配许多不同的字符.
Square brackets let you match one of many different characters. 

168
00:10:25,885 --> 00:10:30,485
所以在这里,我们写个字符串, 比如说"aba",
So here, let's build up a string list something like "aba", 

169
00:10:30,485 --> 00:10:37,360
接着,我想把"a"和"b"换成空.
and I want to substitute "a" and "b" with nothing. 

170
00:10:37,360 --> 00:10:42,504
好的,那么这里我告诉模式要做的
Okay, so here, what I'm telling the pattern to do 

171
00:10:42,504 --> 00:10:47,385
是把任何"a"或"b"字符替换为空.
is to replace any character that is either "a" or "b" with nothing. 

172
00:10:47,385 --> 00:10:52,010
不过即使我把第一个字符变成"b",它仍然会输出"ba".
So if I make the first character "b", it will still produce "ba". 

173
00:10:52,010 --> 00:10:54,560
你可能会想,为什么它只替换了一次?
You might wonder though why did it only replace once? 

174
00:10:54,560 --> 00:10:58,610
这是因为正则表达式,特别是在这种默认模式下,
Well, it's because what regular expressions will do, especially in this default mode, 

175
00:10:58,610 --> 00:11:03,360
每行只会匹配一次,替换一次.
is they will just match the pattern once and then apply the replacement once per line. 

176
00:11:03,360 --> 00:11:05,435
这就是"sed"通常会做的事情.
That is what "sed" normally does. 

177
00:11:05,435 --> 00:11:10,760
你可以使用"g"修饰符,它表示尽可能多的匹配,
You can provide the "g" modifier which says do this as many times as it keeps matching, 

178
00:11:10,760 --> 00:11:16,235
这种情况下会删除整行,因为每个字符都是"a"或"b".
which in this case would erase the entire line because every single character is either an "a" or a "b". 

179
00:11:16,260 --> 00:11:19,885
如果在这里添加一个"c",然后就会移除"c"以外的所有字符,
If I added a "c" here and removed everything but the "c", 

180
00:11:19,885 --> 00:11:24,435
如果我在字符串中间加一些其他字符,那么中间的其他字符都将被保留,
if I added other characters in the middle of this string somewhere, they would all be preserved 

181
00:11:24,435 --> 00:11:27,035
但是"a"或"b"都会被删除.
but anything that is an "a" or a "b" is removed. 

182
00:11:30,382 --> 00:11:35,107
你也可以给这个模式添加修饰符.
You can also do things like add modifiers to this. 

183
00:11:35,107 --> 00:11:44,007
例如,这会做什么?
For example, what would this do? 

184
00:11:44,007 --> 00:11:50,932
它表示我想要零个或多个"ab"字符串,
This is saying I want zero or more of the string "ab", 

185
00:11:50,932 --> 00:11:53,182
然后我要用空替换它们.
and I'm gonna replace them with nothing. 

186
00:11:53,182 --> 00:11:56,882
这意味着如果我有一个独立的"a",它将不会被删除,
This means that if I have a standalone "a", it will not be replaced,

187
00:11:56,882 --> 00:11:59,157
我有一个独立的"b",它也不会被删除,
If I have a standalone "b", it will not be replaced.

188
00:11:59,157 --> 00:12:02,357
但是如果我有"ab"字符串,它将被删除,
But if I have the string "ab", it will be removed.

189
00:12:02,357 --> 00:12:11,550
咦,咋了?这是应该是因为"sed"很蠢.
Which, yeah, what are they? "sed" is stupid. 

190
00:12:11,550 --> 00:12:16,125
这里的"-E"是因为"sed"是一个非常古老的工具,
The "-E" here is because "sed" is a really old tool, 

191
00:12:16,125 --> 00:12:20,100
因此它仅支持非常旧的正则表达式版本.
and so it supports only a very old version of regular expressions. 

192
00:12:20,100 --> 00:12:23,130
通常,你需要使用"-E"运行它,
Generally, you will want to run it with "-E",

193
00:12:23,130 --> 00:12:26,000
这使它使用更现代的语法来支持更多的功能.
which makes it use a more modern syntax that supports more things. 

194
00:12:26,000 --> 00:12:28,775
如果你无法使用"-E",
If you are in a place where you can't, 

195
00:12:28,775 --> 00:12:34,775
你必须在括号前加上"\",以表示转义,
you have to prefix these with backslashes to say 'I want the special meaning of parenthesis,' 

196
00:12:34,775 --> 00:12:39,375
否则,它们只会匹配括号本身,这可能不是你想要的.
otherwise, they will just match a literal parenthesis, which is probably not what you want. 

197
00:12:39,375 --> 00:12:45,950
注意,这里"ab"被替换了,这里"ab"也被替换了,
So notice how this replaced the "ab" here and it replaced the "ab" here, 

198
00:12:45,975 --> 00:12:47,450
但是它留下了这个"c",
but it left this "c", 

199
00:12:47,450 --> 00:12:52,725
而且它也留下了最后的"a",因为这个"a"不再匹配这个模式了.
and it also left the "a" at the end because that "a" does not match this pattern anymore. 

200
00:12:53,125 --> 00:12:56,000
你可以任意组合这些模式.
And you can group these patterns in whatever ways you want. 

201
00:12:56,000 --> 00:12:58,575
也有类似于替换的东西.
You also have things like alternations. 

202
00:12:58,575 --> 00:13:04,350
你可以说,我要删除任何匹配"ab"或"bc"的内容.
You can say anything that matches "ab" or "bc", I want to remove. 

203
00:13:06,054 --> 00:13:09,154
你会发现这个"ab"已经被删除了,
And here you'll notice that this "ab" got removed. 

204
00:13:09,154 --> 00:13:13,304
而这个"bc"虽然也符合模式,
This "bc" did not get removed, even though it matches the pattern, 

205
00:13:13,304 --> 00:13:16,154
但因为"ab"已经率先被删除了,所以它没有被删除.
because the "ab" had already been removed. 

206
00:13:16,154 --> 00:13:18,754
这个"ab"被正确地删除了,
This "ab" is removed right, 

207
00:13:18,754 --> 00:13:19,779
但"c"仍然保留在原地.
but the "c" stays in place.

208
00:13:19,779 --> 00:13:24,529
这个"ab"被删除了,而这个"c"被保留了,因为它仍然不匹配.
This "ab" is removed and this "c" states because it still does not match that. 

209
00:13:24,529 --> 00:13:26,304
如果我这样做,
If I made this, 

210
00:13:26,304 --> 00:13:27,557
如果我删除这个"a",
if I remove this "a", 

211
00:13:27,557 --> 00:13:31,253
那么现在这个"ab"模式就不会匹配到这个"b",
then now this "ab" pattern will not match this "b", 

212
00:13:31,253 --> 00:13:32,504
所以它会被保留,
so it'll be preserved, 

213
00:13:32,504 --> 00:13:35,329
然后"bc"将匹配"bc",就会被删除.
and then "bc" will match "bc" and it'll go away. 

214
00:13:35,379 --> 00:13:40,329
当你第一次接触正则表达式,可能会感觉它们非常复杂,
Regular expressions can be all sorts of complicated when you first encounter them, 

215
00:13:40,329 --> 00:13:44,154
即使你很有经验了,但表达式本身仍然会让人望而生畏.
and even once you get more experience with them, they can be daunting to look at. 

216
00:13:44,154 --> 00:13:49,079
这就是为什么需要使用正则表达式调试器这样的工具,
And this is why very often you want to use something like a regular expression debugger, 

217
00:13:49,079 --> 00:13:50,629
我们稍后会介绍.
which we'll look at in a little bit. 

218
00:13:50,629 --> 00:13:54,529
但现在,让我们试着构建一个表达式,
But first, let's try to make up a pattern that will match the logs 

219
00:13:54,529 --> 00:13:58,154
能匹配我们刚刚处理过的那个日志.
and match the logs that we've been working with so far. 

220
00:13:58,154 --> 00:14:02,579
所以在这里,我将从这个文件中提取出几行,
So here, I'm gonna just sort of extract a couple of lines from this file, 

221
00:14:02,579 --> 00:14:04,254
比如前五行.
let's say the first five. 

222
00:14:04,254 --> 00:14:08,054
这些行现在看起来都是这样的,对吧?
So these lines all now look like this, right? 

223
00:14:08,054 --> 00:14:13,754
我们想要做的是只留下用户名.
And what we want to do is we want to only have the user name. 

224
00:14:13,754 --> 00:14:16,654
那么我们会写成啥样呢?
Okay, so what might this look like? 

225
00:14:16,654 --> 00:14:22,529
好的,我们可以先试着做一件事情.
Well, here's one thing we could try to do. 

226
00:14:27,042 --> 00:14:31,117
让我先拿出一行内容,
Actually, let me show you one, except one thing first. 

227
00:14:31,117 --> 00:14:34,192
比如说
Let me take a line that says something like 

228
00:14:34,192 --> 00:14:38,819
"Diconnected from invalid user 
"Disconnected from invalid user 

229
00:14:38,819 --> 00:14:44,617
Disconnected from 84.211",
Disconnected from maybe 84.211.. whatever." 

230
00:14:44,617 --> 00:14:47,642
这是一个登录行的例子,
Okay, so this is an example of a login line 

231
00:14:47,642 --> 00:14:52,742
其中有人尝试使用用户名"Disconnected from"登录.
where someone tried to login with the username "Disconnected from". 

232
00:14:52,742 --> 00:14:56,242
嗷,少了一个"s".
Missing an "s".

233
00:15:03,229 --> 00:15:07,279
你会发现这个模式实际上删除了用户名,
You'll notice that this actually removed the username as well, 

234
00:15:07,279 --> 00:15:09,879
这是因为当你使用".*"
and this is because when you use ".*"

235
00:15:09,879 --> 00:15:14,032
这种对一个范围进行匹配的正则表达式,它们是贪婪匹配.
and any of these sort of range expressions, indirect expressions, they are greedy. 

236
00:15:14,032 --> 00:15:16,429
即它们会尽可能匹配更多内容.
They will match as much as they can. 

237
00:15:16,429 --> 00:15:21,054
所以在这种情况下,这是我们想要保留的用户名,
So in this case, this was the username that we wanted to retain, 

238
00:15:21,054 --> 00:15:26,379
但是这个模式在这里一直匹配到它第二次出现
but this pattern actually matched all the way up until the second occurrence of it 

239
00:15:26,379 --> 00:15:27,754
(或者说最后一次出现),
(or the last occurrence of it), 

240
00:15:27,779 --> 00:15:31,829
所以它之前的所有内容,包括用户名本身,都被删除了.
and so everything before it, including the username itself, got removed. 

241
00:15:31,829 --> 00:15:35,029
因此,我们需要想一个匹配策略
And so we need to come up with a slightly clever or matching strategy 

242
00:15:35,029 --> 00:15:37,104
一个比".*"更聪明的匹配策略,
than just saying sort of ".*",

243
00:15:37,104 --> 00:15:39,535
不然如果我们遇到特别诡异的输入,
because it means that if we have particularly adversarial input, 

244
00:15:39,579 --> 00:15:41,929
我们可能会得到我们意想不到的结果.
we might end up with something that we didn't expect. 

245
00:15:42,954 --> 00:15:46,204
好的,让我们来看看如何匹配这些行.
Okay, so let's see how we might try to match these lines. 

246
00:15:46,204 --> 00:15:48,804
让我们从头开始.
Let's just do a head-first. 

247
00:15:48,804 --> 00:15:58,104
我们先构建这个正则表达式.
Well, let's try to construct this up from the beginning. 

248
00:15:58,104 --> 00:16:03,054
首先,我们要"-E",对吧?
We first of all know that we want a "-E", right? 

249
00:16:03,054 --> 00:16:06,529
因为我们不想到处都要加"\".
Because we want to not have to put all these "\" everywhere. 

250
00:16:06,529 --> 00:16:09,804
先是"from",
These lines look like they say "from", 

251
00:16:09,804 --> 00:16:13,654
然后有些行写了"invalid",
and then some of them say "invalid", 

252
00:16:13,654 --> 00:16:16,104
但有些行又没有,对吧?
but some of them do not, right? 

253
00:16:16,104 --> 00:16:18,204
这行写了"invalid",那个没有.
This line has "invalid", that one does not. 

254
00:16:18,229 --> 00:16:21,004
这里的"?"表示零或一次,
"?" here is saying zero or one, 

255
00:16:21,004 --> 00:16:25,479
所以我想要0个或1个"invalid ".
so I want zero or zero or one of "invalid ".

256
00:16:26,704 --> 00:16:28,079
然后是"user"?
user?

257
00:16:28,525 --> 00:16:30,350
还有什么?
What else? 

258
00:16:30,350 --> 00:16:33,250
emm,多了一个空格,删掉它.
Well, that's going to be a double space, so we can't have that. 

259
00:16:33,250 --> 00:16:36,675
然后后面有个用户名,
And then there's gonna be some username, 

260
00:16:36,675 --> 00:16:43,025
然后是一个IP地址.
and then there's gonna be what exactly is gonna be what looks like an IP address.

261
00:16:43,025 --> 00:16:50,000
这里我们可以使用区间匹配,匹配0-9和".",对吧?
So here we can use our range syntax and say zero to nine and a dot, right? 

262
00:16:50,000 --> 00:16:54,625
这就是IP地址,我们还要匹配多次.
That's what IP addresses are, and we want many of those. 

263
00:16:54,625 --> 00:16:59,526
然后后面是"port",所以我们只需要匹配一个固定的字符串"port",
Then it says "port," so we're just going to match a literal port 

264
00:16:59,526 --> 00:17:02,275
然后又是0-9匹配多次,
and then another number zero to nine, 

265
00:17:02,275 --> 00:17:05,575
这里使用"+".
and we're going to wand plus of that. 

266
00:17:06,675 --> 00:17:11,400
这里还有一件事儿就是要给正则表达式打锚点.
The other thing we're going to do here is we're going to do what's known as anchoring the regular expression. 

267
00:17:11,425 --> 00:17:14,325
正则表达式中有两个特殊字符:
So, there are two special characters in regular expressions: 

268
00:17:14,325 --> 00:17:18,275
一个是"^",它匹配行的开头,
there's carrot or hat, which matches the beginning of a line, 

269
00:17:18,325 --> 00:17:21,200
还有一个是"$",它匹配行的结尾.
and there's dollar, which matches the end of a line. 

270
00:17:21,200 --> 00:17:26,725
所以我们这样写就是说这个正则表达式必须匹配整行.
So, here we're going to say that this regular expression has to match the complete line. 

271
00:17:26,725 --> 00:17:29,331
我们这样做的原因是,想象一下,
The reason we do this is because imagine that 

272
00:17:29,331 --> 00:17:33,450
如果有人把他们的用户名设置为整条日志文本,
someone made their username the entire log string. 

273
00:17:33,450 --> 00:17:35,975
那么如果你尝试匹配的时候,
Then, if you try to match this pattern, 

274
00:17:35,975 --> 00:17:40,925
它会匹配用户名本身,这不是我们想要的.
it would match the username itself, which is not what we want. 

275
00:17:40,925 --> 00:17:45,950
通常,锚点能加上就加上,以避免那些偶然情况.
Generally, you will want to try to anchor your patterns wherever you can to avoid those kind of oddities. 

276
00:17:45,950 --> 00:17:47,825
好的,让我看看效果.
Okay, let's see what that gave us. 

277
00:17:47,825 --> 00:17:51,450
这删除了许多行,还是留下了一些.
That removed many of the lines but not all of them. 

278
00:17:51,450 --> 00:17:56,775
例如,这个行末有一个"[preauth]",所以我们需要去掉它.
So, this one, for example, includes this "[preauth]" at the end, so we'll want to cut that off. 

279
00:17:56,775 --> 00:18:05,800
空格,"preauth","[]"是特殊字符,我们需要转义它们
If there's a space, "preauth," square brackets are specials, we need to escape them, right? 

280
00:18:05,800 --> 00:18:09,225
现在,让我们看看如果尝试多来几行会发生什么.
Now, let's see what happens if we try more lines of this. 

281
00:18:09,300 --> 00:18:11,650
淦,输出仍然很诡异.
No, it still gets something weird. 

282
00:18:11,650 --> 00:18:15,050
这是因为有些行非空,也就是说这个模式没有匹配上.
Some of these lines are not empty, right, which means that the pattern did not match. 

283
00:18:15,050 --> 00:18:20,650
例如,这一行是"authenticating user",而不是"invalid user".
This one, for example, says "authenticating user" instead of "invalid user." 

284
00:18:20,650 --> 00:18:25,570
那么,我们改成在"user"前匹配"invalid"或"authenticated"
Okay, so as to match "invalid " or "authenticated "

285
00:18:25,570 --> 00:18:29,375
零次或一次,现在如何?
zero or one time before "user," how about now? 

286
00:18:29,375 --> 00:18:32,325
好的,现在看起来很有希望了,
Okay, that looks pretty promising, 

287
00:18:32,400 --> 00:18:35,853
但是这个输出也没啥用,
but this output is not particularly helpful, right? 

288
00:18:35,853 --> 00:18:39,834
这里我们只是成功地删除了日志文件的每一行,
Here we've just erased every line of our log files successfully, 

289
00:18:39,834 --> 00:18:41,450
这并不是非常有用的.
which is not very helpful. 

290
00:18:41,450 --> 00:18:46,675
相反,当我们在匹配用户名时,
Instead, what we really wanted to do is when we match the username, right over here, 

291
00:18:46,675 --> 00:18:49,642
我们真正想要记录的是用户名,
we really wanted to remember what that username was 

292
00:18:49,642 --> 00:18:51,800
因为这才是我们想要输出的内容.
because that is what we want to print out. 

293
00:18:51,800 --> 00:18:54,890
在正则表达式中,
And the way we can do that in regular expressions 

294
00:18:54,890 --> 00:18:57,975
我们可以使用捕获组(capture group)来实现这一点.
is using something like capture groups. 

295
00:18:57,975 --> 00:19:07,100
捕获组可以指定我们关心的值,并在以后重复使用它.
So, capture groups are a way to say that I want to remember this value and reuse it later, 

296
00:19:07,100 --> 00:19:12,250
在正则表达式中,任何带圆括号的表达式
and in regular expressions, any bracketed expression, any parenthesis expression, 

297
00:19:12,250 --> 00:19:14,250
都算是一个捕获组.
is going to be such a capture group. 

298
00:19:14,250 --> 00:19:17,700
我们实际上已经有了一个捕获组,这是第一个组,
So, we already actually have one here, which is this first group, 

299
00:19:17,700 --> 00:19:20,025
现在我们正在创建第二个组.
and now we're creating a second one here. 

300
00:19:20,125 --> 00:19:23,925
请注意,这些括号对匹配没有任何影响,
Notice that these parentheses don't do anything to the matching, right, 

301
00:19:23,925 --> 00:19:26,850
因为它们只是在表示这个表达式是一个整体,
because they're just saying this expression as a unit, 

302
00:19:26,850 --> 00:19:30,475
但是我们没有在后面加上任何修饰符,所以只匹配一次.
but we don't have any modifiers after it, so it's just match one-time. 

303
00:19:30,475 --> 00:19:36,300
捕获组之所以有用,
And the reason matching groups are useful or capture groups are useful 

304
00:19:36,300 --> 00:19:39,350
是因为你可以在替换时引用它们.
is because you can refer back to them in the replacement. 

305
00:19:39,400 --> 00:19:42,875
在这里,我可以说"\2".
So, in the replacement here, I can say "\2". 

306
00:19:42,875 --> 00:19:45,900
这是引用捕获组的方式.
This is the way that you refer to the name of a capture group. 

307
00:19:45,900 --> 00:19:49,525
这里我是说先匹配整行,
In this case, I'm saying match the entire line, 

308
00:19:49,525 --> 00:19:55,700
然后在替换中放入你在第二个捕获组匹配的值.
and then in the replacement, put in the value you captured in the second capture group. 

309
00:19:55,700 --> 00:19:57,950
记住,这是第一个捕获组,
Remember, this is the first capture group, 

310
00:19:57,950 --> 00:19:59,525
而这是第二个捕获组.
and this is the second one.

311
00:20:00,375 --> 00:20:02,350
这样可以得到所有的用户名.
And this gives me all the usernames. 

312
00:20:02,350 --> 00:20:04,775
现在回顾一下我们写的内容,
Now,  if you look back at what we wrote, 

313
00:20:04,775 --> 00:20:07,750
这非常复杂,对吧?
this is pretty complicated, right? 

314
00:20:07,750 --> 00:20:09,731
但是我们这是我们一步步尝试得来的,
It might make sense now that we walk through it 

315
00:20:09,731 --> 00:20:11,550
知道为什么它必须是这样的,
and why it had to be the way it was, 

316
00:20:11,550 --> 00:20:15,175
但具体要搞懂这坨东西执行起来如何,还不明了.
but this is not obvious that this is how these lines work. 

317
00:20:15,175 --> 00:20:20,850
这个时候可以借助正则调试器.
And this is where a regular expression debugger can come in really, really handy. 

318
00:20:20,850 --> 00:20:24,200
这里有一个调试器,网上也有很多.
So we have one here, there are many online, 

319
00:20:24,200 --> 00:20:28,325
我已经预先填好了我们刚刚使用的表达式.
but here I've sort of pre-filled in this expression that we just used. 

320
00:20:28,325 --> 00:20:33,100
可以注意到,它会告诉我现在所有的匹配情况.
And notice that it tells me what all the matching does, 

321
00:20:33,100 --> 00:20:38,300
这个窗口的字体有点小,
in fact, now this window is a little small with this font size, 

322
00:20:38,300 --> 00:20:44,146
这里有一些解释,是说
But if I do....Here, this explanation says

323
00:20:44,146 --> 00:20:48,425
".*"可以匹配零个或多个任意字符,
".*" matches any character between zero and unlimited times, 

324
00:20:48,425 --> 00:20:54,050
然后是"Disconnected from",后面是一个捕获组,
followed by "Disconnected from" literally followed by a capture group, 

325
00:20:54,050 --> 00:20:56,150
它会给你解释所有的东西.
and then walks you through all the stuff. 

326
00:20:56,150 --> 00:20:57,925
这是它的一个功能,
And that's one thing, 

327
00:20:57,925 --> 00:21:00,194
你还可以给出测试字符串,
but it also lets you've given a test string 

328
00:21:00,194 --> 00:21:03,450
然后正则表达式会与每个测试字符串进行匹配,
and then matches the pattern against every single test string 

329
00:21:03,450 --> 00:21:07,750
并突出显示不同的捕获组.
that you give and highlights what the different capture groups, for example, are. 

330
00:21:07,750 --> 00:21:12,750
在这里,我们将用户设置成了一个捕获组,对吧?
So here, we made user a capture group, right? 

331
00:21:13,200 --> 00:21:15,607
它会说整个字符串都匹配了,
So it'll say okay, the full string matched, 

332
00:21:15,607 --> 00:21:17,600
整个字符串都是蓝色的,表明它匹配成功了.
the whole thing is blue, so it matched. 

333
00:21:17,600 --> 00:21:21,300
绿色是第一个捕获组,红色是第二个捕获组,
Green is the first capture group, red is the second capture group, 

334
00:21:21,300 --> 00:21:25,400
这是第三个捕获组,因为"preauth"也被放在括号中.
and this is the third because "preauth" was also put into parenthesis. 

335
00:21:25,400 --> 00:21:28,975
这用来调试正则表达式就很nice 了.
And this can be a handy way to try to debug your regular expressions. 

336
00:21:29,000 --> 00:21:33,075
例如,如果我输入"Disconnected from",
For example, if I put "Disconnected from", 

337
00:21:33,075 --> 00:21:37,850
然后在这里新加一行,
and let's add a new line here, 

338
00:21:39,225 --> 00:21:43,250
让用户名变成"Disconnected from",
and I make the username "Disconnected from",

339
00:21:43,250 --> 00:21:46,400
现在这一行的用户名已经变成"Disconnect from".
now that line already had the username be "Disconnect from". 

340
00:21:46,400 --> 00:21:48,725
很好,已经被我预判到了.
Great, here I'm thinking ahead. 

341
00:21:48,725 --> 00:21:55,300
你会注意到,使用这个模式,就不再是一个问题,
You'll notice that with this pattern, this was no longer a problem 

342
00:21:55,300 --> 00:21:57,300
因为它成功匹配了用户名.
because it got matched the username. 

343
00:21:57,300 --> 00:22:06,275
如果我们把这行变成用户名会发生什么?
What happens if we take this entire line or this entire line and make that the username? 

344
00:22:06,275 --> 00:22:08,525
猜猜看?
Now what happens? 

345
00:22:10,125 --> 00:22:13,125
非常令人迷惑,对吧?
It gets really confused, right? 

346
00:22:13,250 --> 00:22:16,413
所以这就是为什么正则表达式很难弄对,
So this is where regular expressions can be a pain to get right 

347
00:22:16,413 --> 00:22:19,450
它现在尝试匹配...
because it now tries to match ...

348
00:22:19,450 --> 00:22:23,250
它匹配第一次出现的用户名,
It matches the first place where username appears, 

349
00:22:23,275 --> 00:22:25,336
似乎是第一个"invalid".
or the first "invalid" in this case,

350
00:22:25,336 --> 00:22:28,825
emm,不对,是第二个"invalid",因为这是贪婪匹配.
the second invalid, because this is greedy. 

351
00:22:28,825 --> 00:22:32,500
我们可以通过在这里加一个"?"来使它变成非贪婪.
We can make this non-greedy by putting a "?" here. 

352
00:22:32,500 --> 00:22:37,446
如果你在"+"或"*"后面加上一个"?",
So if you suffix a "+" or a "*" with a "?", 

353
00:22:37,446 --> 00:22:39,500
它就变成了一个非贪婪匹配.
it becomes a non-greedy match. 

354
00:22:39,500 --> 00:22:41,900
这意味着它将不会匹配尽可能多的字符.
So it will not try to match as much as possible. 

355
00:22:41,900 --> 00:22:44,250
然后你会发现,这个表达式被正确解析了,
And then you see that this actually gets parsed correctly 

356
00:22:44,250 --> 00:22:48,325
因为这个".*"会停在第一个"Disconnected from",
because this ".*" will stop at the first "Disconnected from", 

357
00:22:48,325 --> 00:22:51,664
这个"Disconnect from"是由ssh生成的,
which is the one that's actually emitted by SSH, 

358
00:22:51,664 --> 00:22:54,100
就是我们日志里记录的那个.
the one that actually appears in our logs. 

359
00:22:55,700 --> 00:23:01,650
讲到现在,你已经知道正则表达式可以非常复杂,
As you can probably tell from the explanation of this so far,\N regular expressions can get really complicated, 

360
00:23:01,650 --> 00:23:06,425
并且你可能需要在正则表达式中使用各种奇怪的符号.
and there are all sorts of weird modifiers that you might have to apply in your pattern. 

361
00:23:06,425 --> 00:23:09,661
学习它们的好方法是从简单的表达式开始,
The only way to really learn them is to start with simple ones 

362
00:23:09,661 --> 00:23:11,950
然后逐步构建,直到它们匹配你所需的内容.
and then build them up until they match what you need. 

363
00:23:11,950 --> 00:23:14,033
通常你只需要处理一些
Often you're just doing some like 

364
00:23:14,033 --> 00:23:16,475
类似于我们在这里提取用户名的一次性工作,
one-off job like when we're hacking out the usernames here, 

365
00:23:16,475 --> 00:23:19,600
而不需要关心所有特殊的条件,对吧?
and you don't need to care about all the special conditions, right?

366
00:23:19,675 --> 00:23:24,900
不必担心某个人的ssh用户名是否完全匹配你的登录格式.
Don't have to care about someone having the SSH username perfectly match your login format. 

367
00:23:24,900 --> 00:23:28,925
那可能不是什么重要的事情,因为你只是想找到用户名.
That's probably not something that matters because you're just trying to find the usernames. 

368
00:23:28,925 --> 00:23:31,150
但是正则表达式确实非常强大,
But regular expressions are really powerful, 

369
00:23:31,150 --> 00:23:34,125
如果你做的是真正重要的事情,你就要小心.
and you want to be careful if you're doing something where it actually matters. 

370
00:23:34,125 --> 00:23:35,200
你有问题吗?
You had a question ?

371
00:23:40,148 --> 00:23:45,773
默认情况下,正则表达式只会按行匹配,
regular expressions by default only match per line anyway. 

372
00:23:46,250 --> 00:23:49,200
不会跨行匹配.
They will not match across new lines. 

373
00:23:56,750 --> 00:24:02,050
所以"sed"的工作方式是逐行操作,
So, the way that "sed" works is that it operates per line, 

374
00:24:02,050 --> 00:24:07,300
所以"sed"将为每一行去匹配这个表达式.
and so "sed" will do this expression for every line. 

375
00:24:08,800 --> 00:24:12,675
好的,关于正则表达式或者这个模式有什么问题吗?
Okay, questions about regular expressions or this pattern so far? 

376
00:24:12,675 --> 00:24:16,975
这是一个复杂的模式,如果感觉困惑,不要担心.
It is a complicated pattern, so if it feels confusing, like don't be worried about it. 

377
00:24:16,975 --> 00:24:18,300
下课后可以自己去正则调试器去试试看.
Look at it in the debugger later. 

378
00:24:29,600 --> 00:24:36,925
记住一点,我们在这里假设用户只能修改他们的用户名.
Keep in mind that we're assuming here that the user only has control over their username. 

379
00:24:37,050 --> 00:24:43,150
所以他们能做的最坏的事儿就是把整条记录都作为用户名.
So the worst that they could do is take like this entire entry and make that the username. 

380
00:24:43,150 --> 00:24:47,825
看看会发生什么.会像这样,对吧
Let's see what happens, right? 

381
00:24:47,825 --> 00:24:48,625
这就是它的工作原理.
So that's how it works. 

382
00:24:48,625 --> 00:24:52,007
原因在于这个"?"的作用,
And the reason for this is this "?" 

383
00:24:52,007 --> 00:24:55,100
它意味着一旦我们遇到"Disconnected from",
means that the moment we hit the disconnect keyword, 

384
00:24:55,100 --> 00:24:58,375
就立刻匹配后面的模式.
we start parsing the rest of the pattern , right?

385
00:24:58,375 --> 00:25:00,841
而ssh在用户的可编辑内容之前
And the first occurrence of "Disconnected"

386
00:25:00,841 --> 00:25:04,175
就打印了第一次出现的"Disconnected".
is printed by ssh before anything the user controls. 

387
00:25:04,175 --> 00:25:08,325
因此,在这种特定情况下,模式也能正确匹配.
So in this particular instance, even this will not confuse the pattern. 

388
00:25:08,375 --> 00:25:09,650
请提问?
Yep.

389
00:25:15,525 --> 00:25:20,350
emm...所以如果你正在...
Well, so if you're writing a... 

390
00:25:20,450 --> 00:25:23,286
如果你在进行数据整理时使用这种奇怪的匹配方式,
This sort of odd matching will, 

391
00:25:23,286 --> 00:25:29,500
通常不会涉及到安全问题,
in general, when you're doing data wrangling, is like not security-related, 

392
00:25:29,500 --> 00:25:32,350
但可能会导致你得到非常奇怪的数据.
but it might mean that you get really weird data back. 

393
00:25:32,350 --> 00:25:36,950
如果你要绘制数据图表,可能会漏掉重要的数据点,
And so if you're doing something like plotting data, you might drop data points that matter. 

394
00:25:36,950 --> 00:25:39,100
或者解析出错误的数字,
You might parse out the wrong number, 

395
00:25:39,100 --> 00:25:42,875
然后你的图表中就会出现原始数据中没有的数据点.
and then your plot suddenly has data points that weren't in the original data. 

396
00:25:42,875 --> 00:25:47,150
因此,如果你发现自己在编写复杂的正则表达式,
And so it's more that if you find yourself writing a complicated regular expression, 

397
00:25:47,150 --> 00:25:50,175
请仔细检查它是否确实匹配了你想要匹配的内容.
like double-check that it's actually matching what you think it's matching. 

398
00:25:50,225 --> 00:25:59,225
即使不考虑安全性,正则表达式的模式也可以非常复杂.
And even if it's not security-related, as you can imagine, these patterns can get really complicated. 

399
00:25:59,250 --> 00:26:01,876
例如,使用正则表达式
Like, for example, there's a big debate about 

400
00:26:01,876 --> 00:26:04,850
匹配电子邮件地址就存在很大的争议.
how do you match an email address with a regular expression? 

401
00:26:04,850 --> 00:26:06,550
你可能会想到类似于这样的模式:
And you might think of something like this. 

402
00:26:06,550 --> 00:26:10,034
这是一个非常简单的例子,
So this is a very straightforward one that just says 

403
00:26:10,034 --> 00:26:13,375
只说字母和数字,下划线分数和百分比,
letters and numbers and underscore scores and percent 

404
00:26:13,375 --> 00:26:17,950
然后一个"+",因为在Gmail中,email地址可以包含"+".
followed by a "+" because in Gmail, you can have pluses in email addresses with a suffix. 

405
00:26:17,950 --> 00:26:23,250
在这种情况下,"+"只是用于表示任意数量的这些字符,
In this case, the "+" is just for any number of these, 

406
00:26:23,250 --> 00:26:24,345
但至少要有一个,
but at least one

407
00:26:24,345 --> 00:26:27,000
因为"@"前为空的电子邮件地址是无效的,
 because you can't have an email address that doesn't have anything before the address, 

408
00:26:27,000 --> 00:26:29,675
后面域名的规则也类似.
and then similarly after the domain, right?  

409
00:26:29,675 --> 00:26:33,800
顶级域名必须至少包含两个字符,并且不能包含数字.
And the top-level domain has to be at least two characters and can't include digits.

410
00:26:33,800 --> 00:26:35,225
你可以使用".com",
Right? You can have it ".com", 

411
00:26:35,225 --> 00:26:36,575
但不能使用".7".
but you can't have a ".7". 

412
00:26:37,350 --> 00:26:39,525
但事实证明,这种方法也不是完全正确的.
It turns out this is not really correct. 

413
00:26:39,525 --> 00:26:43,275
有很多有效的电子邮件地址无法被匹配,
There are a bunch of valid email addresses that will not be matched by this, 

414
00:26:43,275 --> 00:26:45,775
也有很多无效的电子邮件地址可以被匹配.
and there are a bunch of invalid email addresses that will be matched by this. 

415
00:26:45,775 --> 00:26:50,400
因此,有许多建议,
So there are many, many suggestions, 

416
00:26:50,400 --> 00:26:55,775
有些人已经建立了完整的测试套件来尝试找到最佳的正则表达式,
and there are people who've built like full test suites to try to see which regular expression is best, 

417
00:26:55,800 --> 00:27:00,150
而这个特定的正则表达式是用于 URL 的.
and this particular one is for URLs. 

418
00:27:00,150 --> 00:27:02,232
类似的正则表达式也适用于电子邮件地址,
There are similar ones for email 

419
00:27:02,232 --> 00:27:05,400
他们发现最好的正则表达式是这个.
where they found that the best one is this one. 

420
00:27:05,400 --> 00:27:08,450
我不建议你试图理解这个模式,
I don't recommend you trying to understand this pattern, 

421
00:27:08,450 --> 00:27:13,925
但这个模式似乎几乎可以完美地匹配
but this one apparently will almost perfectly match what 

422
00:27:13,925 --> 00:27:17,525
互联网标准中的有效电子邮件地址,
the internet standard for email addresses says as a valid email address, 

423
00:27:17,525 --> 00:27:20,675
包括各种奇怪的Unicode编码.
and that includes all sorts of weird Unicode code points. 

424
00:27:20,775 --> 00:27:24,100
这只是说,正则表达式可能非常复杂,
This is just to say, regular expressions can be really hairy, 

425
00:27:24,100 --> 00:27:25,797
如果你写出这样复杂的表达式,
and if you end up somewhere like this,

426
00:27:25,797 --> 00:27:28,300
那么可能存在不用正则表达式的更好做法.
 there's probably a better way to do it. 

427
00:27:28,300 --> 00:27:32,495
例如,如果你发现自己试图解析HTML
For example, if you find yourself trying to parse HTML or something, 

428
00:27:32,495 --> 00:27:39,870
或JSON之类的内容,你应该使用不同的工具.
or parse JSON where there are expressions, you should probably use a different tool. 

429
00:27:39,870 --> 00:27:44,800
笔记里也有一个练习,要求你不使用正则表达式完成这个任务.
And there is an exercise that has you do this, not with regular expressions. 

430
00:27:47,710 --> 00:27:51,343
这里有很多建议.
yep, there is also lots of suggestions.

431
00:27:51,343 --> 00:27:55,275
如果你想了解它们的工作原理,
They give you deep dives into how they work if you want to look that up.

432
00:27:55,275 --> 00:27:57,375
可以查看课程笔记.
it's in the lecture notes.

433
00:27:57,825 --> 00:28:02,525
现在我们有了用户名列表,
Okay, so now we have the list of usernames. 

434
00:28:02,525 --> 00:28:04,650
让我们回到数据整理.
Let's go back to data wrangling. 

435
00:28:04,650 --> 00:28:08,425
对我来说,这个用户名列表依然不友好.
This list of usernames is still not that interesting to me. 

436
00:28:08,425 --> 00:28:10,750
让我们看看有多少行.
Let's see how many lines there are. 

437
00:28:10,750 --> 00:28:19,000
如果我使用{\rcode}wc -l{\r}命令,可以计算出一共有198000行.
So if I do "wc -l", there are 198,000 lines. 

438
00:28:19,000 --> 00:28:23,325
"wc"(word count)是单词计数程序,"-l"是让它计算行数.
wc is the word count program, -l makes it count the number of lines. 

439
00:28:23,325 --> 00:28:25,350
这里有很多行.
This is a lot of lines. 

440
00:28:25,350 --> 00:28:28,850
如果我开始滚动浏览它们,这仍然没啥用.
If I start scrolling through them, that still doesn't really help me. 

441
00:28:28,850 --> 00:28:33,785
我需要统计数据以及把这些数据做某种聚合,
I need statistics over this, I need aggregates of some kind, 

442
00:28:33,785 --> 00:28:39,532
"sed"工具用途广泛,它是一个完整的编程语言,
and the "sed" tool is useful for many things, it gives you a full programming language, 

443
00:28:39,532 --> 00:28:44,532
可以做奇怪的事情,比如插入文本或只输出匹配的行,
it can do weird things like insert text or only print matching lines, 

444
00:28:44,532 --> 00:28:47,336
但"sed"并不是完美的工具.
but it's not necessarily the perfect tool for everything. 

445
00:28:47,336 --> 00:28:49,486
有时候有更好的工具.
Sometimes there are better tools. 

446
00:28:49,486 --> 00:28:52,850
例如,要编写一个行计数器.
For example, you could write a line counter in sed.

447
00:28:53,737 --> 00:28:56,495
你不应该只是使用"sed",
You just should never, "sed" is a terrible programming language 

448
00:28:56,495 --> 00:28:59,391
除了搜索和替换之外,它是一个糟糕的编程语言,
except for searching and replacing, 

449
00:28:59,391 --> 00:29:01,729
还有其他好用的工具.
but there are other useful tools. 

450
00:29:01,729 --> 00:29:05,327
例如,有一个叫做"sort"的工具.
So, for example, there's a tool called "sort". 

451
00:29:05,327 --> 00:29:09,544
当然"sort"有时候也不是很好用
So ,"sort"...this is also not can be very helpful.

452
00:29:09,544 --> 00:29:12,383
但是"sort"可以接受很多行的输入,
but "sort" takes a bunch of lines of input,

453
00:29:12,383 --> 00:29:14,486
再把它们排序,然后把排序好的行输出.
sorts them and then prints them to your output. 

454
00:29:14,486 --> 00:29:18,551
因此,这里我现在得到了有序列表.
So in this case, I now get the sorted output of that list. 

455
00:29:18,551 --> 00:29:21,822
它仍然有20万行,对我来说仍然不是很友好,
It is still 200,000 lines long, so it's still not very helpful to me, 

456
00:29:21,822 --> 00:29:25,981
但现在我可以将它与一个叫做"uniq"的工具组合使用.
but now I can combine it with a tool called "uniq". 

457
00:29:25,981 --> 00:29:32,990
"uniq"会查看一个排序后的行列表,然后它会去除那些重复的行.
"uniq" will look at a sorted list of lines and it will only print those that are unique. 

458
00:29:32,990 --> 00:29:37,430
即如果有多个相同的行,则仅打印一次.
So if you have multiple instances of any given line, it will only print it once. 

459
00:29:37,430 --> 00:29:40,187
然后我可以使用"uniq -c"
And then I can say "uniq -c", 

460
00:29:40,187 --> 00:29:47,102
这将计算任何重复行的重复次数并消除它们.
so this is going to say count the number of duplicates for any lines that are duplicated and eliminate them. 

461
00:29:47,243 --> 00:29:48,598
这是什么样子?
What does this look like? 

462
00:29:48,598 --> 00:29:52,336
好的,如果我运行它,需要等一段时间.
if I run it, it's going to take a while. 

463
00:29:52,336 --> 00:29:59,087
有13个"zzz"用户名,有10个"zxvf"用户名等等.
There were thirteen "zzz" usernames, there were ten "zxvf" usernames, etc. 

464
00:29:59,087 --> 00:30:00,654
我可以滚动浏览这个列表.
There, and I can scroll through this. 

465
00:30:00,654 --> 00:30:02,710
这仍然是一个非常长的列表,
This is still a very long list, right, 

466
00:30:02,710 --> 00:30:06,542
但至少现在它比以前更有条理了一些.
but at least now it's a little bit more collated than it was. 

467
00:30:06,635 --> 00:30:09,673
让我们看看现在我有多少行.
Let's see how many lines I'm down to now. 

468
00:30:12,476 --> 00:30:15,093
好的,有24,000行.
Okay, 24,000 lines.   

469
00:30:15,093 --> 00:30:17,850
但是仍然有太多垃圾信息,
It's still too much, it's not useful information to me, 

470
00:30:17,850 --> 00:30:21,074
我可以使用更多的工具来缩小范围.
But I can keep burning down this with more tools. 

471
00:30:21,074 --> 00:30:25,700
例如,我可能想知道哪个用户名出现的次数最多.
For example, what I might care about is which user names have been used the most. 

472
00:30:25,700 --> 00:30:28,174
那么,我可以再次使用"sort",
Well, I can do "sort" again 

473
00:30:28,174 --> 00:30:33,457
然后我可以说我想在输入的第一列上进行数字排序,
and I can say I want a numeric sort on the first column of the input, 

474
00:30:33,457 --> 00:30:36,542
因此"-n"用来数字排序,
so "-n" says numeric sort,

475
00:30:36,542 --> 00:30:42,195
"-k"可以让你选择输入中以空格为分隔符的列来执行排序.
"-k" lets you select a white space separated column from the input to sort by. 

476
00:30:42,195 --> 00:30:45,139
我在这里使用"1,1",
And the reason I'm giving "1,1" here,

477
00:30:45,139 --> 00:30:48,737
是因为我想从第一列开始并在第一列停止排序.
is because I want to start at the first column and stop at the first column. 

478
00:30:48,737 --> 00:30:52,756
或者,我可以说依据所有的列进行排序,
Alternatively, I could say I want you to sort by this list of columns, 

479
00:30:52,756 --> 00:30:55,560
但在这种情况下,我只想按第一列排序.
but in this case, I just want to sort by that column. 

480
00:30:55,560 --> 00:31:00,607
然后我只想要最后的十行.
And then I want only the ten last lines. 

481
00:31:00,607 --> 00:31:05,560
默认情况下,"sort"会按升序输出,
So, "sort" by default will output in ascending order,  

482
00:31:05,560 --> 00:31:09,785
因此具有次数最多的将位于底部,
so the ones with the highest counts are gonna be at the bottom,

483
00:31:09,785 --> 00:31:12,149
然后我只想要最后的十行.
and then I want only lost ten lines. 

484
00:31:13,458 --> 00:31:15,287
现在当我执行这个命令时,
And now when I run this, 

485
00:31:15,287 --> 00:31:17,710
我确实得到了一些我想要的数据.
I actually get a useful bit of data. 

486
00:31:17,710 --> 00:31:22,430
对,它告诉我用户名"root"有11,000次的登录尝试,
Right, it tells me there were eleven thousand login attempts with the username "root", 

487
00:31:22,430 --> 00:31:28,224
有4,000次使用用户名"123456"等等.
there were four thousand with "123456" as the username, etc. 

488
00:31:28,224 --> 00:31:31,168
这非常方便,对吧?
And this is pretty handy, right? 

489
00:31:31,168 --> 00:31:36,822
现在这个巨大的日志文件已经为我提供了我想要的信息.
And now suddenly this giant log file actually produces useful information for me. 

490
00:31:36,822 --> 00:31:39,439
这就是我真正想从那个日志文件中得到的信息.
This is what I really want from that log file.

491
00:31:39,439 --> 00:31:46,916
现在,也许我想禁用"root"用户,
Now, maybe I want to just like do a quick disabling of "root",\N for example, for ssh login on my machine, 

492
00:31:46,916 --> 00:31:49,383
我建议你也这样做.
which I recommend you will do, by the way. 

493
00:31:51,402 --> 00:31:55,342
在这种情况下,我们实际上不需要"sort"的"-k"排序,
In this particular case, we don't actually need the "-k" for "sort" 

494
00:31:55,342 --> 00:31:58,832
因为默认情况下,"sort"会按整行排序,
because "sort" by default will sort by the entire line, 

495
00:31:58,832 --> 00:32:00,514
而数字恰好排在第一列.
and the number happens to come first. 

496
00:32:00,514 --> 00:32:03,178
但是了解这些额外的标志是有用的,
But it's useful to know about these additional flags, 

497
00:32:03,178 --> 00:32:06,403
你可能会想知道,我怎么知道这些标志存在?
How would I know that these programs even exist? 

498
00:32:06,403 --> 00:32:08,403
我怎么知道这些程序存在的?
and you might wonder, well, how would I know that these flags exist? 

499
00:32:08,505 --> 00:32:13,598
好吧,通常是从像这样的课程中得到的信息.
Well, the programs usually pick up just from being told about them in classes like here. 

500
00:32:13,598 --> 00:32:16,169
这些标志通常表示
The flags are usually like, 

501
00:32:16,169 --> 00:32:20,234
我想按照某一标准进行排序,但经常不是按照整行
"I want to sort by something that is not the full line."

502
00:32:20,234 --> 00:32:25,000
你的第一反应应该是{\rcode}man sort{\r},
Your first instinct should be to type main sort and then read through the page, 

503
00:32:25,000 --> 00:32:26,777
很快你就会知道这些东西,
and then very quickly will tell you, 

504
00:32:26,777 --> 00:32:30,748
"这是怎么选中一行,以及这是怎么按数字排序的"
"Here's how to select a pretty good column. Here's how to sort by a number, etc."

505
00:32:32,709 --> 00:32:38,317
好的,如果现在我有了这个前20名的名单,
Okay, what if now that I have this top, let's say top 20 list,

506
00:32:38,317 --> 00:32:41,333
假设我实际上并不关心计数,
let's say I don't actually care about the counts, 

507
00:32:41,333 --> 00:32:44,719
我只想要一个","分隔的用户名列表,
I just want like a comma separated list of the user names 

508
00:32:44,719 --> 00:32:49,859
因为我要每天给自己发一些电子邮件,说明一些信息,
because I'm gonna send it to myself by email every day or something like that. 

509
00:32:49,859 --> 00:32:52,476
例如:"这些是用户名前20"
Like, these are the top 20 usernames. 

510
00:32:52,476 --> 00:32:55,887
那么我可以这样做.
Well, I can do this. 

511
00:32:58,271 --> 00:33:01,074
又出现了很多诡异的命令,
Okay, that's a lot more weird commands, 

512
00:33:01,074 --> 00:33:03,037
但是你们应该知道这些.
but their commands that are useful to know about. 

513
00:33:03,037 --> 00:33:08,084
"awk"是一种基于列的流处理器.
So, "awk" is a column-based stream processor. 

514
00:33:08,084 --> 00:33:14,673
我们讲了"sed",它是一种流编辑器,主要编辑输入中的文本.
So, we talked about sed, which is a stream editor, so it tries to edit text primarily in the inputs. 

515
00:33:14,673 --> 00:33:18,598
另一方面,"awk"也让你编辑文本.
Awk, on the other hand, also lets you edit text. 

516
00:33:18,598 --> 00:33:20,280
它仍然提供了一种完整的编程语言,
It is still a full programming language, 

517
00:33:20,280 --> 00:33:22,757
但它更专注处理列数据.
but it's more focused on columnar data. 

518
00:33:22,757 --> 00:33:28,598
因此,在这种情况下,"awk"默认将输入解析为以空格为分隔符的列
So, in this case, "awk" by default will parse its input in whitespace-separated columns, 

519
00:33:28,598 --> 00:33:31,401
然后再单独操作这些列.
and then that you operate on those columns separately. 

520
00:33:31,401 --> 00:33:35,093
在这种情况下,我正在说仅打印第二列,也就是用户名.
In this case, I'm saying just print the second column, which is the username. 

521
00:33:35,140 --> 00:33:36,215
是吧?
Right?

522
00:33:36,215 --> 00:33:40,187
"paste"是一个命令,它可以把多个行合并在一起
"paste" is a command that takes a bunch of lines 

523
00:33:40,187 --> 00:33:46,542
使其成为一行,使用"-s"命令可以分割输入
and pastes them together into a single line, that's the "-s" with the delimiter comma. 

524
00:33:46,542 --> 00:33:48,824
因此,在这种情况下,对于这个问题,
So, in this case, for this, 

525
00:33:48,824 --> 00:33:52,440
我可以用"-sd,"获得一个以","分隔的用户排名列表,
I want to get a comma-separated list of the top usernames, 

526
00:33:52,440 --> 00:33:55,187
然后我可以物尽其用.
which I can then do whatever useful thing I might want. 

527
00:33:55,233 --> 00:34:00,981
也许我想将其放入用户黑名单的配置文件中啥的.
Maybe I want to stick this in a config file of disallowed usernames or something along those lines. 

528
00:34:00,981 --> 00:34:04,749
我还想多讲一些有关"awk"的操作,
Awk is worth talking a little bit more about 

529
00:34:04,749 --> 00:34:10,093
对于这种数据整理,它非常给力.
because it turns out to be a really powerful language for this kind of data wrangling. 

530
00:34:10,093 --> 00:34:15,140
我们简要提到了"print $2"做了什么,
We mentioned briefly what this "print $2" does, 

531
00:34:15,140 --> 00:34:20,654
但事实上,你可以用"awk"做一些非常非常复杂的事情.
but it turns out that for awk, you can do some really, really fancy things. 

532
00:34:20,654 --> 00:34:23,878
例如,让我们回到只有用户名的地方.
For example, let's go back to here where we just have the usernames. 

533
00:34:23,878 --> 00:34:32,149
我认为我们仍需要使用"sort"和"uniq",否则列表会很长,
I say let's still do "sort" and "uniq" because we don't, the list gets far too long, 

534
00:34:32,149 --> 00:34:37,430
而且我只想输出与特定模式匹配的用户名.
and let's say that I only want to print the usernames that match a particular pattern. 

535
00:34:37,430 --> 00:34:41,903
例如,emmmm....
Let's say, for example, that I want....

536
00:34:45,823 --> 00:34:48,430
"uniq -c"
"uniq -c"

537
00:34:48,430 --> 00:34:58,692
我想查看所有仅出现一次且以"c"开头以"e"结尾的用户名.
I want all of the usernames that only appear once and that start with a "c" and end with an "e". 

538
00:34:58,785 --> 00:35:01,262
虽然这很奇怪,
That's a really weird thing to look for, 

539
00:35:01,262 --> 00:35:04,159
但总体来说,它非常简单易懂.
but in all, it's really simple to express. 

540
00:35:04,159 --> 00:35:06,963
我可以说我希望第一列为1,
I can say I want the first column to be 1, 

541
00:35:07,103 --> 00:35:14,346
第二列匹配以下正则表达式.
and I want the second column to match the following regular expression. 

542
00:35:20,234 --> 00:35:23,364
嘿,这可能只是"."就行了,
Hey, this could probably just be dot, 

543
00:35:25,888 --> 00:35:28,785
然后我想整行打印.
and then I want to print the whole line. 

544
00:35:30,981 --> 00:35:33,269
所以,除非我弄错了什么,
So, unless I mess something up, 

545
00:35:33,269 --> 00:35:38,037
不然我会得到以"c"开头以"e"结尾
this will give me all the usernames that start with a "c", end with an "e", 

546
00:35:38,037 --> 00:35:40,140
并且在日志中仅出现一次的用户名.
and only appear once in my log. 

547
00:35:41,495 --> 00:35:45,140
这个数据整理本身可能没啥实际用处.
Now, that might not be a very useful thing to do with the data. 

548
00:35:45,140 --> 00:35:48,878
这节课我就是试图向你展示实用的工具,
What I'm trying to do in this lecture is show you the kind of tools that are available, 

549
00:35:48,878 --> 00:35:54,252
即使我举的例子很奇怪,但这种模式也不是很复杂.
and in this particular case, this pattern is not that complicated, even though what we're doing is sort of weird. 

550
00:35:54,299 --> 00:36:00,093
这是因为在Linux上,特别是在命令行工具中,
This is because very often on Linux, with Linux tools in particular and command-line tools in general, 

551
00:36:00,093 --> 00:36:04,813
工具通常是基于输入行和输出行构建的,
the tools are built to be based on lines of input and lines of output, 

552
00:36:04,813 --> 00:36:08,458
而这些行通常会有很多列,
and very often, those lines are going to have multiple columns, 

553
00:36:08,458 --> 00:36:10,981
而"awk"非常适合操作列.
and "awk" is great for operating over columns. 

554
00:36:16,168 --> 00:36:24,392
现在,"awk"不仅逐行匹配,
Now, "awk" is not just able to do things like match per line, 

555
00:36:24,392 --> 00:36:29,299
而且还可以让你做,例如,我想知道这些的数量.
but it lets you do things like let's say I want the number of these. 

556
00:36:29,299 --> 00:36:32,149
我想知道有多少用户名与此模式匹配.
I want to know how many usernames match this pattern. 

557
00:36:32,149 --> 00:36:35,327
很好,"wc -l"可以正常工作.
Well, I can do "wc -l" that works just fine. 

558
00:36:36,308 --> 00:36:38,785
有31个这样的用户名,
Alright, there are 31 such usernames, 

559
00:36:38,785 --> 00:36:41,028
但"awk"是一种编程语言.
but "awk" is a programming language. 

560
00:36:41,028 --> 00:36:45,794
你可能永远不会用到它,
This is something that you will probably never end up doing yourself, 

561
00:36:45,841 --> 00:36:47,803
但是重要的是要知道你可以做到.
but it's important to know that you can. 

562
00:36:47,803 --> 00:36:52,289
有时候这样做还是有用的.
Every now and again, it is actually useful to know about these. 

563
00:36:53,551 --> 00:36:58,878
我刚刚意识到这在我的屏幕上可读性很差,
This might be hard to read on my screen, I just realized. 

564
00:37:00,934 --> 00:37:04,018
我马上来处理一下.
Let me try to fix that in a second. 

565
00:37:07,055 --> 00:37:09,812
让我们运行一下...
Let's do... 

566
00:37:09,859 --> 00:37:15,233
好吧,显然"fish"不想让我这样做.
yeah, Apparently "fish" does not want me to do that. 

567
00:37:15,233 --> 00:37:20,981
那么,"BEGIN"在第一行的开头被匹配.
Um, so here "BEGIN" is a special pattern that only matches the zeroth line. 

568
00:37:20,981 --> 00:37:26,448
"END"在最后一行的最后被匹配.
"END" is a special pattern that only matches after the last line. 

569
00:37:26,448 --> 00:37:30,233
然后这是一个普通的正则匹配模式,用于逐行匹配.
And then this is gonna be a normal pattern that's matched against every line. 

570
00:37:30,233 --> 00:37:34,906
所以我在这里所说的是,从第0行开始,将变量"rows"设置为零.
So what I'm saying here is on the zeroth line, set the variable "rows" to zero. 

571
00:37:34,906 --> 00:37:38,878
碰到匹配此模式的行时,"rows"的值就会增加.
On every line that matches this pattern, increment "rows". 

572
00:37:38,878 --> 00:37:43,831
直到匹配到最后一行,打印"rows"的值.
And after you have matched the last line, print the value of "rows". 

573
00:37:43,831 --> 00:37:47,149
这和运行"wc -l"一样的,
And this will have the same effect as running "wc -l", 

574
00:37:47,149 --> 00:37:48,504
不过这个是全部用"awk"实现的.
but all within awk. 

575
00:37:48,504 --> 00:37:52,149
像"wc -l"就已经效果非常棒了,
Its particular instance like "wc -l" is just fine, 

576
00:37:52,149 --> 00:37:57,990
但有时你可能想要维护一个字典或map之类的.
but sometimes you want to do things like you want to might want to keep a dictionary or a map of some kind. 

577
00:37:57,990 --> 00:37:59,719
你可能想要统计一些东西.
You might want to compute statistics. 

578
00:37:59,719 --> 00:38:03,738
或者你可能想要这样做:我想要此模式的第二个匹配项.
You might want to do things like, I want the second match of this pattern. 

579
00:38:03,738 --> 00:38:06,396
因此,你需要一个有状态的匹配器,
So you need a stateful matcher like 

580
00:38:06,396 --> 00:38:07,311
可以忽略第一个匹配项,
ignore the first match 

581
00:38:07,311 --> 00:38:09,299
然后打印第二个匹配项之后的所有的匹配项.
but then print everything following the second match. 

582
00:38:09,299 --> 00:38:13,411
对于这些简单的任务,"awk"编程可以很有用.
And for that, this kind of simple programming in "awk" can be useful to know about. 

583
00:38:15,794 --> 00:38:18,732
实际上,我们可以在这种模式中,
In fact, we could, in this pattern, 

584
00:38:18,732 --> 00:38:25,514
摆脱最初用于生成此文件的"sed", "sort", "uniq"和"grep",
get rid of "sed", "sort", "uniq" and "grep" that we originally used to produce this file, 

585
00:38:25,514 --> 00:38:26,635
并全部使用"awk"来完成.
and do it all in awk. 

586
00:38:26,635 --> 00:38:28,504
但你可能不想这样做.
But you probably don't want to do that. 

587
00:38:28,504 --> 00:38:31,308
因为这可能得不偿失.
It would be probably too painful to be worth it. 

588
00:38:33,241 --> 00:38:39,549
再来讲讲其他非常好用的工具.
It's worth talking a little bit about the other kinds of tools \N that you might want to use on the command line. 

589
00:38:39,549 --> 00:38:43,054
其中之一是一个非常好用的程序,称为"bc".
The first of these is a really handy program called "bc". 

590
00:38:43,100 --> 00:38:46,605
我记得"bc"是伯克利计算器
So "bc" is the "Berkeley calculator", I believe. 

591
00:38:46,605 --> 00:38:48,054
{\rcode}man bc{\r}
"man bc". 

592
00:38:48,972 --> 00:38:51,822
我记得"bc"最初应该就是来自伯克利计算器.
I think "bc" is originally from Berkeley calculator . 

593
00:38:51,822 --> 00:38:54,885
它是一个非常简洁的命令行计算器,
Anyway,it is a very simple command-line calculator 

594
00:38:54,885 --> 00:38:57,056
它不会给你提示符让你输入,
but instead of giving you a prompt, 

595
00:38:57,056 --> 00:38:58,683
而是从标准输入流中读取.
it reads from standard in. 

596
00:38:58,683 --> 00:39:03,528
所以我可以像这样做:{\rcode}echo "1+2" | bc -l{\r}.
So I can do something like 'echo "1+2" and pipe it to bc -l. 

597
00:39:03,528 --> 00:39:07,085
(要加"-l",)因为许多程序的默认模式通常
because many of these programs normally operate in like 

598
00:39:07,085 --> 00:39:09,719
不是很好用,会有奇怪的问题.
a stupid mode where they're unhelpful. 

599
00:39:09,719 --> 00:39:13,458
所以它在这里打印了3.
So here it prints 3. 

600
00:39:13,458 --> 00:39:14,906
非常哇塞.
Wow, very impressive. 

601
00:39:14,906 --> 00:39:17,663
这可以非常方便.
But it turns out this can be really handy. 

602
00:39:17,663 --> 00:39:20,514
想象一下你有一个很多行的文件,
Imagine you have a file with a bunch of lines, 

603
00:39:20,514 --> 00:39:28,214
比如说,我不确定,这个文件...
let's say something like, oh, I don't know, this file. 

604
00:39:28,214 --> 00:39:33,925
假设我想要求出登录的总次数,
And let's say I want to sum up the number of logins, 

605
00:39:33,925 --> 00:39:37,289
把出现不止一次的用户的次数加起来.
the number of usernames that have not been used only once. 

606
00:39:37,289 --> 00:39:45,374
接下来,对于计数不为1的用户名,把他们的次数输出.
Alright, so the ones where the count is not equal to one, I want to print just the count. 

607
00:39:46,215 --> 00:39:51,448
对的,这是我,给我所有非单次使用用户名的计数.
Right, this is me, give me the counts for all the non single-use usernames. 

608
00:39:51,448 --> 00:39:54,299
然后我想知道总数是多少.
And then I want to know how many are there of these. 

609
00:39:54,299 --> 00:39:59,299
请注意,我不能只数行,因为每行都有对应的次数.
Notice that I can't just count the lines, that wouldn't work right because there are numbers on each line. 

610
00:39:59,299 --> 00:40:00,654
我需要把他们加起来.
I want to sum. 

611
00:40:00,654 --> 00:40:04,719
好的,我可以使用"paste"一边粘贴输入,一边加上"+".
Well, I can use "paste" to paste by "+". 

612
00:40:04,719 --> 00:40:09,579
这样前进把所有的次数用"+"连起来了.
So this paste every line together into a plus expression, right? 

613
00:40:09,579 --> 00:40:15,177
这是一个算术表达式,因此我可以将其用管道传递到"bc -l".
And this is now an arithmetic expression, so I can pipe it through bc -l. 

614
00:40:15,177 --> 00:40:22,944
非单次登录的登录总数是十九万一千多次.
And now there have been 191,000 logins that share to username with at least one other login. 

615
00:40:22,944 --> 00:40:26,261
再次说明,这可能不是你想关注的事情,
Again, probably not something you really care about, 

616
00:40:26,261 --> 00:40:30,607
但这只是为了向你展示你可以相当容易地进行数据提取.
but this is just to show you that you can extract this data pretty easily. 

617
00:40:30,607 --> 00:40:35,981
你还可以用这个做很多其他的事情.
And there's all sorts of other stuff you can do with this. 

618
00:40:35,981 --> 00:40:39,345
例如,有一些工具可以让你对输入进行统计分析.
For example, there are tools that let you compute statistics over inputs. 

619
00:40:39,345 --> 00:40:46,588
因此,对于我刚刚打印的这个数字列表,
So for example, for this list of numbers, just the numbers that I just printed out,

620
00:40:46,588 --> 00:40:50,130
就这些分散的数据而言
Just the distribution numbers,

621
00:40:50,140 --> 00:40:54,554
我可以通过使用R语言完成这样的事情.
I could do things like use R. 

622
00:40:54,554 --> 00:40:58,364
R是一种专门用于统计分析的编程语言.
R is a separate programming language that's specifically built for statistical analysis. 

623
00:40:58,364 --> 00:41:03,598
我可以这样,让我看看我做对了没有......
And I can say, let's see if I got this right...

624
00:41:03,598 --> 00:41:09,756
这又是一种你需要特意去学一下的编程语言,
this is again a different programming language that you would have to learn, 

625
00:41:10,607 --> 00:41:19,999
但如果你已经了解R,或者你也可以将它们管道传递给其他语言,比如这样.
but if you already know R or you can pipe them through other languages too, like so. 

626
00:41:21,636 --> 00:41:27,243
这个命令会在输入流中给我汇总统计数据.
This gives me summary statistics over that input stream of numbers. 

627
00:41:27,383 --> 00:41:32,243
因此,每个用户名的登录尝试次数的中位数为3,
So, the median number of login attempts per username is 3, 

628
00:41:32,243 --> 00:41:35,224
最大值为10,000+,我们之前看过了,
the max is 10,000 that was route we saw before, 

629
00:41:35,224 --> 00:41:36,963
最后告诉我平均值为8.
and it tells me the average was 8. 

630
00:41:37,337 --> 00:41:39,907
这些例子可能不是太有意义,
For this might not matter particular instance, 

631
00:41:39,907 --> 00:41:41,355
同时这些数字可能不是很有趣,
and these might not be interesting numbers, 

632
00:41:41,355 --> 00:41:45,000
但是如果你正在处理统计脚本的输出
but if you're looking at things like output from your benchmarking script 

633
00:41:45,000 --> 00:41:49,346
或其他一些有数值分布的输出,并且想要查看它们,
or something else where you have some numerical distribution and you want to look at them, 

634
00:41:49,346 --> 00:41:51,495
这些工具就非常有用.
these tools are really handy. 

635
00:41:51,636 --> 00:41:55,748
我们甚至可以绘制一些简单的图标,对吧.
We can even do some simple plotting if we wanted to, right?

636
00:41:55,748 --> 00:41:58,505
这里有一些数字.
So this has a bunch of numbers. 

637
00:41:58,505 --> 00:42:07,196
让我们回到我们的"sort -nk1,1",并只保留最前面5个.
Let's go back to our "sort -nk1,1" and look at only the two top 5. 

638
00:42:07,196 --> 00:42:14,673
"gnuplot"是一种从标准输入中获取内容的绘图工具.
gnuplot is a plotter that lets you take things from standard in. 

639
00:42:16,401 --> 00:42:20,513
我并不指望你会所有这些编程语言,
I'm not expecting you to know all of these programming languages 

640
00:42:20,513 --> 00:42:24,756
因为它们确实都是独立的一门语言,
because they really are programming languages in their own right, 

641
00:42:24,859 --> 00:42:27,055
只是向你展示一下你可以使用的工具.
but it's just to show you what is possible. 

642
00:42:29,159 --> 00:42:32,617
现在,这是一个直方图,
So, this is now a histogram of 

643
00:42:32,617 --> 00:42:36,365
一个关于"自1月1日以来我的服务器上前5的用户名的
how many times each of the top 5 usernames 

644
00:42:36,365 --> 00:42:39,102
使用次数"的直方图,
have been used for my server since January 1st, 

645
00:42:39,392 --> 00:42:42,523
而这只用了一行命令.
and it's just one command-line. 

646
00:42:42,523 --> 00:42:44,953
虽然有点复杂,
It's a somewhat complicated command line, 

647
00:42:44,953 --> 00:42:47,336
但它只有一行
but it's just one command-line thing that you can do.

648
00:42:50,654 --> 00:42:54,159
在最后的几分钟里,
There are two special types of data wrangling 

649
00:42:54,159 --> 00:42:57,103
我想讲一下两种特殊的数据整理方法
that I want to talk to you about in the last little bit of time that we have, 

650
00:42:57,103 --> 00:43:01,775
第一种是命令行参数整理
and the first one is command-line argument wrangling. 

651
00:43:01,869 --> 00:43:09,906
有时,你可能会像我们在上一堂课中看到的"find"那样,
Sometimes, you might have something that, actually, we looked at in the last lecture, 

652
00:43:09,906 --> 00:43:13,551
会产生一串文件,
like you have things like find that produce a list of files 

653
00:43:13,551 --> 00:43:21,962
或者你可能想要产生一些参数作为你的基准测试脚本的参数,
or maybe something that produces a list of arguments for your benchmarking script, 

654
00:43:21,962 --> 00:43:24,766
例如你想使用特定的参数分布运行它.
like you want to run it with a particular distribution of arguments. 

655
00:43:24,766 --> 00:43:26,168
假设你有一个脚本,
Let's say you had a script 

656
00:43:26,168 --> 00:43:29,486
它会在每行打印出运行特定项目所需的迭代次数,
that printed the number of iterations to run a particular project, 

657
00:43:29,486 --> 00:43:31,771
并且你想要使用指数分布或其他分布
and you wanted, like, an exponential distribution or something,

658
00:43:31,771 --> 00:43:34,392
对这些迭代次数进行采样,
 and this prints the number of iterations on each line, 

659
00:43:34,392 --> 00:43:37,103
在采样到的每个迭代次数上运行基准测试.
and you were to run your benchmark for each one. 

660
00:43:37,103 --> 00:43:40,280
好的,这里有一个工具叫做"xargs",它是你的好帮手.
Well, here is a tool called xargs that's your friend. 

661
00:43:40,280 --> 00:43:46,635
"xargs"可以将输入的每行都转换成参数.
xargs takes lines of input and turns them into arguments, 

662
00:43:46,916 --> 00:43:48,598
这可能看起来有些奇怪.
and this might look a little weird. 

663
00:43:48,598 --> 00:43:51,495
我来举一个例子.
See if I can come up with a good example for this. 

664
00:43:51,495 --> 00:43:53,364
我用Rust编程,
So, I program in Rust, 

665
00:43:53,364 --> 00:43:57,383
而Rust可以安装多个版本的编译器.
And rust lets you install multiple versions of the compiler. 

666
00:43:57,383 --> 00:44:00,738
在这种情况下,你可以看到我安装了稳定版,beta版
So in this case, you can see that I have stable beta, 

667
00:44:00,738 --> 00:44:04,299
和几个较早的稳定版本,
I have a couple of earlier stable releases, 

668
00:44:04,299 --> 00:44:06,261
还有不同的日期的nightly版本.
and I've launched a different dated nightlys

669
00:44:06,261 --> 00:44:08,317
所有版本的编译器都是可以用的
And this is all very well, 

670
00:44:08,317 --> 00:44:09,213
但是随着时间的推移,
but over time

671
00:44:09,213 --> 00:44:14,813
我不需要比如去年3月的Nightly版本了.
 like I don't really need the nightly version from like March of last year anymore. 

672
00:44:14,813 --> 00:44:16,805
我可能想不时地清理一下这些版本,
I can probably delete that every now and again, 

673
00:44:16,916 --> 00:44:18,411
或者我想清理一下这些东西.
and maybe I want to clean these up a little. 

674
00:44:18,411 --> 00:44:23,472
好吧,这是一个多行列表,所以我可以先找出nightly版本,
Well, this is a list of lines, so I can get for nightly, 

675
00:44:23,472 --> 00:44:25,472
然后把它们删掉.
I can get rid of...

676
00:44:25,514 --> 00:44:31,542
"-v"表示不匹配,我不想匹配到当前最新的nightly版本.
So "-v" is don't match, I don't want to match to the current nightly. 

677
00:44:31,542 --> 00:44:34,719
好的,这是过期的nightly列表.
Okay, so this is a list of dated nightlys. 

678
00:44:34,766 --> 00:44:37,243
我只想要2019年后的版本,
Maybe I want only the ones from 2019, 

679
00:44:39,019 --> 00:44:44,393
现在我想卸载这一个个工具链.
and now I want to remove each of these tool chains for my machine. 

680
00:44:44,393 --> 00:44:47,687
我可以手动复制每个工具链的名称并粘贴到...
I could copy paste each one into...

681
00:44:47,687 --> 00:44:55,935
到"rustup toolchain remove"或"uninstall",对吧?
there's a "rustup toolchain remove" or "uninstall" maybe ,toolchain uninstall, right? 

682
00:44:55,935 --> 00:44:59,112
所以我可以手动输入每一个名字,或者复制/粘贴它们,
So I could manually type out the name of each one or copy/paste them, 

683
00:44:59,112 --> 00:45:02,804
但是我现在有了这个列表,手动输入不是很麻烦吗.
but that's getting gets annoying really quickly because I have the list right here. 

684
00:45:02,804 --> 00:45:13,084
那么现在问题转换为,我应该怎么去掉它的后缀?
So instead, how about I said away this sort of this suffix that it adds? 

685
00:45:13,131 --> 00:45:17,103
看这里,接下来我会用"xargs"
Right, so now it's just that, and then I use "xargs". 

686
00:45:17,103 --> 00:45:22,523
"xargs"会将一系列输入列表转换成参数.
So "xargs" takes a list of inputs and turns them into arguments. 

687
00:45:22,523 --> 00:45:29,206
所以我想把这些参数传递给"rustup toolchain uninstall",
So I want this to become arguments to "rustup toolchain uninstall", 

688
00:45:29,206 --> 00:45:32,303
但为了方便起见,我会加上"echo"
and just for my own sanity's sake, I'm gonna make this echo

689
00:45:32,303 --> 00:45:34,860
以便查看要运行的命令是什么.
 just so it's going to show which command it's gonna run. 

690
00:45:34,860 --> 00:45:39,141
嗯,这些信息可能不是很有用,而且可读性不强
Well, it's relatively unhelpful, but are hard to read at least. 

691
00:45:39,141 --> 00:45:41,374
但至少你可以看到即将执行的命令.
You see the command it's going to execute. 

692
00:45:41,374 --> 00:45:44,673
如果我去掉这个"echo",将会执行"rustup toolchain uninstall",
If I remove this echo, it's "rustup toolchain uninstall", 

693
00:45:44,673 --> 00:45:48,177
nightly的列表就会作为该程序的参数.
and then the list of nightlys as arguments to that program. 

694
00:45:48,177 --> 00:45:54,065
这样,如果我运行它,就会卸载所有工具链,而不必逐个复制粘贴它们.
And so if I run this, it uninstalls every tool chain instead of me having to copy paste them. 

695
00:45:54,766 --> 00:45:56,402
因此,这是一个例子,
So this is one example 

696
00:45:56,402 --> 00:46:00,374
说明数据整理可以用于除了查看数据以外的任务.
where this kind of data wrangling actually can be useful for other tasks than just looking at data. 

697
00:46:00,374 --> 00:46:02,850
它只是从一个形式的数据转换到另一种.
It's just going from one format to another. 

698
00:46:02,850 --> 00:46:05,327
你也可以整理二进制数据.
You can also wrangle binary data. 

699
00:46:05,327 --> 00:46:09,159
比如一些视频和图像,
So a good example of this is stuff like videos and images 

700
00:46:09,159 --> 00:46:14,149
你可能想整点儿活儿.
where you might actually want to operate over them in some interesting way. 

701
00:46:14,149 --> 00:46:16,168
例如,有一个叫做"ffmpeg"的工具.
So for example, there's a tool called "ffmpeg". 

702
00:46:16,168 --> 00:46:20,981
"ffmpeg"用于编码和解码视频,某种程度上也可以处理图像.
"ffmpeg" is for encoding and decoding video and to some extent images. 

703
00:46:20,981 --> 00:46:25,327
我将设置它的日志级别为"panic",不然它会输出很多东西.
I'm gonna set its log level to panic because otherwise it prints a bunch of stuff. 

704
00:46:25,327 --> 00:46:28,925
我希望它从"/dev/video0"读取,
I want it to read from /dev/video0, 

705
00:46:28,925 --> 00:46:32,289
这是我录制视频的网络摄像头设备,
which is my video of my webcam video device, 

706
00:46:32,383 --> 00:46:38,224
我想要获取第一帧,换句话说我只需要得到一张照片,
and I wanted to take the first frame, so I just wanted to take a picture, 

707
00:46:38,224 --> 00:46:43,551
但不是单帧视频文件,
and I wanted to take an image rather than a single frame video file, 

708
00:46:43,551 --> 00:46:46,215
然后我希望把它输出.
and I wanted to print its output. 

709
00:46:46,215 --> 00:46:48,785
所以这张图片被捕获到标准输出.
So the imaged captures to stand output

710
00:46:48,785 --> 00:46:54,252
"-"通常是告诉程序使用标准输入/输出而不用文件.
"-" is usually the way you tell the program to use standard input or output rather than a given file. 

711
00:46:54,252 --> 00:46:55,747
这个参数在这里想要一个文件名,
So here it expects a file name, 

712
00:46:55,747 --> 00:46:59,532
而"-"在这种情况下就替代文件名表示标准输出.
and the "file name -" means standard output in this context. 

713
00:46:59,532 --> 00:47:03,037
然后,我想用管道把它传输到一个叫做"convert"的程序.
And then I want to pipe that through a parameter called "convert". 

714
00:47:03,037 --> 00:47:06,215
"convert"是一个图像处理程序.
"convert" is an image manipulation program. 

715
00:47:06,215 --> 00:47:13,972
我想告诉"convert"从标准输入读取,并将图像转换为灰度图,
I want to tell "convert" to read from standard input and turn the image into the colorspace gray, 

716
00:47:13,972 --> 00:47:20,747
然后将图像写入"-",也就是标准输出.
and then write the resulting image into the file -, which is standard output. 

717
00:47:20,841 --> 00:47:24,097
然后我想接给"gzip";
And I don't want to pipe that into gzip

718
00:47:24,097 --> 00:47:26,862
它将压缩这个图像文件,
we're just gonna compress this image file, 

719
00:47:26,916 --> 00:47:31,261
它也在标准输入/输出流上操作.
and that's also going to just operate on standard input, standard output. 

720
00:47:31,261 --> 00:47:35,934
然后,我将把它传输到我的远程服务器,
And then I'm going to pipe that to my remote server, 

721
00:47:35,934 --> 00:47:39,860
并在那里解压缩该图像,
and on that, I'm going to decode that image, 

722
00:47:39,860 --> 00:47:43,504
然后存储该图像的副本.
and then I'm gonna store a copy of that image. 

723
00:47:43,504 --> 00:47:48,645
"tee"会读取输入,然后输出到文件和标准输出中.
So remember, tee reads input, prints it to standard out and to a file. 

724
00:47:48,645 --> 00:47:53,598
这就得到解码后的图像副本"copy.png",
This is gonna make a copy of the decoded image file as "copy.png", 

725
00:47:54,953 --> 00:47:57,523
继续沿着管道传递.
and then it's gonna continue to stream that out. 

726
00:47:57,523 --> 00:48:01,215
现在我将把它传递回本地,
So now I'm gonna bring that back into a local stream, 

727
00:48:01,215 --> 00:48:06,729
并在在图片查看器中显示.
and here I'm going to display that in an image display. 

728
00:48:06,729 --> 00:48:08,458
让我们看看是否有效.
Err, let's see if that works. 

729
00:48:10,747 --> 00:48:14,788
嘿,好的,现在它通过服务器进行了往返,
Hey, right, so this now did a round-trip to my server

730
00:48:14,788 --> 00:48:17,990
然后通过管道返回,
 and then came back over pipes, 

731
00:48:17,990 --> 00:48:25,280
此外,理论上,我的服务器上有这张图解码后的副本.
and there's now a computer, there's a decompressed version of this file, at least in theory, on my server. 

732
00:48:25,280 --> 00:48:30,280
让我们看看它是否存在:{\rcode}scp tsp copy.png .{\r}
Let's see if that's there: "scp tsp copy.png .", 

733
00:48:30,327 --> 00:48:33,738
啊哦,少了":"
and ...

734
00:48:36,402 --> 00:48:40,747
就是这样,同样的文件出现在了服务器上,我们的管道生效了.
Yeah, hey, same file ended up on the server, so our pipeline worked. 

735
00:48:41,121 --> 00:48:43,691
再次强调,这是一个简单的例子,
Again, this is a sort of silly example, 

736
00:48:43,691 --> 00:48:46,900
但它让你看到了这些管道的强大,
but let's you see the power of building these pipelines

737
00:48:46,900 --> 00:48:49,298
这些管道传递的不必是文本数据,
where it doesn't have to be textual data; 

738
00:48:49,298 --> 00:48:51,765
它只是将任何格式的数据转换为另一种格式.
it's just going from data in any format to any other. 

739
00:48:51,775 --> 00:48:53,037
例如,
Like, for example, 

740
00:48:53,037 --> 00:48:56,175
如果我想,我可以使用{\rcode}cat /dev/video0{\r},
if I wanted to, I can do "cat  /dev/video0"

741
00:48:56,175 --> 00:49:00,093
然后将其传送到Anish的服务器上,
and then pipe that to a server that Anish controls, 

742
00:49:00,093 --> 00:49:05,420
然后他可以把他用管道接到视频播放器上,然后就可以观看该视频了.
and then he could watch that video stream by piping it into a video player on his machine. 

743
00:49:05,467 --> 00:49:07,710
只要我们想,我们就可以做到.
If we wanted to,right? 

744
00:49:07,710 --> 00:49:10,233
只要这些工具存在就可以实现
It just need to know that these things exist. 

745
00:49:12,009 --> 00:49:14,719
今天依然有一些练习题,
There are a bunch of exercises for this lab, 

746
00:49:14,719 --> 00:49:17,416
其中一些需要你有一个
and some of them rely on you having a data source that 

747
00:49:17,416 --> 00:49:20,701
例如Mac OS或Linux上的日志的数据源.
looks a little bit like a log on Mac OS and Linux. 

748
00:49:20,701 --> 00:49:22,757
我们提供了一些命令,供你实验,
We give you some commands you can try to experiment with, 

749
00:49:22,757 --> 00:49:27,009
但请记住,你使用的数据源不是那么重要.
but keep in mind that it's not that important exactly what data source you use. 

750
00:49:27,009 --> 00:49:31,402
更重要的是找到一些你认为有趣的数据源,
This is more finding some data source where you think there might be an interesting signal, 

751
00:49:31,402 --> 00:49:33,738
然后尝试从中提取一些有趣的东西,这就是所有练习的目的.
and then try to extract something interesting from it. 

752
00:49:33,738 --> 00:49:36,355
这就是我们这节课的内容了
That is what all of the exercises are about. 

753
00:49:36,355 --> 00:49:40,198
因为周一是马丁·路德·金纪念日,
We will not have class on Monday because it's MLK Day, 

754
00:49:40,198 --> 00:49:43,925
所以下一次课是星期二,到时候我们会讲述命令行环境.
so next lecture will be Tuesday on command line environments. 

755
00:49:43,925 --> 00:49:46,381
大家对我们目前讲解的内容
Any questions about what we've covered so far

756
00:49:46,381 --> 00:49:49,532
比如管道传输或是正则表达式啥的有什么问题吗?
or the pipelines or regular expressions? 

757
00:49:49,532 --> 00:49:53,831
我强烈推荐你们好好学学正则表达式,
I really recommend that you look into regular expressions and try to learn them. 

758
00:49:53,831 --> 00:49:57,897
它们非常方便,不仅在这里使用,而且在编程中也很实用.
They are extremely handy, both for this and in programming in general, 

759
00:49:57,897 --> 00:50:01,915
如果有任何问题,请在办公时间来提问,我们会帮助你们的.
and if you have any questions, come to office hours, and we'll help you out.

